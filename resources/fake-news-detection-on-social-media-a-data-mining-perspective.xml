<?xml version="1.0" encoding="UTF-8"?>
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta />
    <article-meta>
      <title-group>
        <article-title>Fake News Detection on Social Media: A Data Mining Perspective</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Kai Shuy</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Amy Slivaz</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Suhang Wangy</string-name>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Jiliang Tang \</string-name>
          <email>tangjili@msu.edu</email>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Huan Liuy</string-name>
          <email>huan.liug@asu.edu</email>
        </contrib>
      </contrib-group>
      <abstract>
        <p />
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec-1">
      <title>-</title>
      <p>Social media for news consumption is a double-edged sword.</p>
      <p>On the one hand, its low cost, easy access, and rapid
dissem2 ination of information lead people to seek out and consume
p news from social media. On the other hand, it enables the
e wide spread of \fake news", i.e., low quality news with
inS tentionally false information. The extensive spread of fake
news has the potential for extremely negative impacts on
3 individuals and society. Therefore, fake news detection on
] social media has recently become an emerging research that
I is attracting tremendous attention. Fake news detection
.S on social media presents unique characteristics and
chals lenges that make existing detection algorithms from
tradic tional news media ine ective or not applicable. First, fake
[ news is intentionally written to mislead readers to believe
false information, which makes it di cult and nontrivial to
3 detect based on news content; therefore, we need to include
v
7 auxiliary information, such as user social engagements on
6 social media, to help make a determination. Second,
ex9 ploiting this auxiliary information is challenging in and of
1 itself as users' social engagements with fake news produce
0 data that is big, incomplete, unstructured, and noisy.
Be. cause the issue of fake news detection on social media is both
8 challenging and relevant, we conducted this survey to
fur0 ther facilitate research on the problem. In this survey, we
7 present a comprehensive review of detecting fake news on
:1 social media, including fake news characterizations on
psyv chology and social theories, existing algorithms from a data
i mining perspective, evaluation metrics and representative
X datasets. We also discuss related research areas, open
probra lems, and future research directions for fake news detection
on social media.</p>
    </sec>
    <sec id="sec-2">
      <title>1. INTRODUCTION</title>
      <p>As an increasing amount of our lives is spent interacting
online through social media platforms, more and more
people tend to seek out and consume news from social media
rather than traditional news organizations. The reasons for
this change in consumption behaviors are inherent in the
nature of these social media platforms: (i) it is often more
timely and less expensive to consume news on social media
compared with traditional news media, such as newspapers
or television; and (ii) it is easier to further share, comment
on, and discuss the news with friends or other readers on
social media. For example, 62 percent of U.S. adults get
news on social media in 2016, while in 2012, only 49
percent reported seeing news on social media1. It was also
found that social media now outperforms television as the
major news source2. Despite the advantages provided by
social media, the quality of news on social media is lower
than traditional news organizations. However, because it
is cheap to provide news online and much faster and easier
to disseminate through social media, large volumes of fake
news, i.e., those news articles with intentionally false
information, are produced online for a variety of purposes, such
as nancial and political gain. It was estimated that over 1
million tweets are related to fake news \Pizzagate"3 by the
end of the presidential election. Given the prevalence of this
new phenomenon, \Fake news" was even named the word of
the year by the Macquarie dictionary in 2016.</p>
      <p>
        The extensive spread of fake news can have a serious
negative impact on individuals and society. First, fake news can
break the authenticity balance of the news ecosystem. For
example, it is evident that the most popular fake news was
even more widely spread on Facebook than the most
popular authentic mainstream news during the U.S. 2016
president election4. Second, fake news intentionally persuades
consumers to accept biased or false beliefs. Fake news is
usually manipulated by propagandists to convey political
messages or in uence. For example, some report shows that
Russia has created fake accounts and social bots to spread
false stories5. Third, fake news changes the way people
interpret and respond to real news. For example, some fake
news was just created to trigger people's distrust and make
them confused, impeding their abilities to di erentiate what
is true from what is not6. To help mitigate the negative
effects caused by fake news{both to bene t the public and
the news ecosystem{It's critical that we develop methods to
automatically detect fake news on social media.
1http://www.journalism.org/2016/05/26/news-use-acrosssocial-media-platforms-2016/
2http://www.bbc.com/news/uk-36528256
3https://en.wikipedia.org/wiki/Pizzagate conspiracy theory
4https://www.buzzfeed.com/craigsilverman/viralfake-election-news-outperformed-real-news-onfacebook?utm term=.nrg0WA1VP0#.gjJyKapW5y
5http://time.com/4783932/inside-russia-social-media-waramerica/
6https://www.nytimes.com/2016/11/28/opinion/fakenews-and-the-internet-shell-game.html? r=0
Detecting fake news on social media poses several new and
challenging research problems. Though fake news itself is
not a new problem{nations or groups have been using the
news media to execute propaganda or in uence operations
for centuries{the rise of web-generated news on social
media makes fake news a more powerful force that challenges
traditional journalistic norms. There are several
characteristics of this problem that make it uniquely challenging for
automated detection. First, fake news is intentionally
written to mislead readers, which makes it nontrivial to detect
simply based on news content. The content of fake news is
rather diverse in terms of topics, styles and media platforms,
and fake news attempts to distort truth with diverse
linguistic styles while simultaneously mocking true news. For
example, fake news may cite true evidence within the
incorrect context to support a non-factual claim [
        <xref ref-type="bibr" rid="ref22">22</xref>
        ]. Thus,
existing hand-crafted and data-speci c textual features are
generally not su cient for fake news detection. Other
auxiliary information must also be applied to improve
detection, such as knowledge base and user social engagements.
Second, exploiting this auxiliary information actually leads
to another critical challenge: the quality of the data itself.
Fake news is usually related to newly emerging, time-critical
events, which may not have been properly veri ed by
existing knowledge bases due to the lack of corroborating
evidence or claims. In addition, users' social engagements
with fake news produce data that is big, incomplete,
unstructured, and noisy [79]. E ective methods to di
erentiate credible users, extract useful post features and exploit
network interactions are an open area of research and need
further investigations.
      </p>
      <p>In this article, we present an overview of fake news detection
and discuss promising research directions. The key
motivations of this survey are summarized as follows:</p>
      <p>Fake news on social media has been occurring for
several years; however, there is no agreed upon de nition
of the term \fake news". To better guide the future
directions of fake news detection research, appropriate
clari cations are necessary.</p>
      <p>Social media has proved to be a powerful source for
fake news dissemination. There are some emerging
patterns that can be utilized for fake news detection
in social media. A review on existing fake news
detection methods under various social media scenarios can
provide a basic understanding on the state-of-the-art
fake news detection methods.</p>
      <p>Fake news detection on social media is still in the early
age of development, and there are still many
challenging issues that need further investigations. It is
necessary to discuss potential research directions that can
improve fake news detection and mitigation
capabilities.</p>
      <p>To facilitate research in fake news detection on social
media, in this survey we will review two aspects of the fake
news detection problem: characterization and detection. As
shown in Figure 1, we will rst describe the background of
the fake news detection problem using theories and
properties from psychology and social studies; then we present
the detection approaches. Our major contributions of this
survey are summarized as follows:
We discuss the narrow and broad de nitions of fake
news that cover most existing de nitions in the
literature and further present the unique characteristics of
fake news on social media and its implications
compared with the traditional media;
We give an overview of existing fake news detection
methods with a principled way to group representative
methods into di erent categories; and
We discuss several open issues and provide future
directions of fake news detection in social media.</p>
      <p>The remainder of this survey is organized as follows. In
Section 2, we present the de nition of fake news and
characterize it by comparing di erent theories and properties in
both traditional and social media. In Section 3, we continue
to formally de ne the fake news detection problem and
summarize the methods to detect fake news. In Section 4, we
discuss the datasets and evaluation metrics used by existing
methods. We brie y introduce areas related to fake news
detection on social media in Section 5. Finally, we discuss the
open issues and future directions in Section 6 and conclude
this survey in Section 7.
2.</p>
    </sec>
    <sec id="sec-3">
      <title>FAKE NEWS CHARACTERIZATION</title>
      <p>In this section, we introduce the basic social and
psychological theories related to fake news and discuss more advanced
patterns introduced by social media. Speci cally, we rst
discuss various de nitions of fake news and di erentiate
related concepts that are usually misunderstood as fake news.
We then describe di erent aspects of fake news on
traditional media and the new patterns found on social media.
2.1</p>
    </sec>
    <sec id="sec-4">
      <title>Definitions of Fake News</title>
      <p>
        Fake news has existed for a very long time, nearly the same
amount of time as news began to circulate widely after the
printing press was invented in 14397. However, there is no
agreed de nition of the term \fake news". Therefore, we rst
discuss and compare some widely used de nitions of fake
news in the existing literature, and provide our de nition of
fake news that will be used for the remainder of this survey.
A narrow de nition of fake news is news articles that are
intentionally and veri ably false and could mislead readers [
        <xref ref-type="bibr" rid="ref2">2</xref>
        ].
There are two key features of this de nition: authenticity
and intent. First, fake news includes false information that
can be veri ed as such. Second, fake news is created with
dishonest intention to mislead consumers. This de nition
has been widely adopted in recent studies [57; 17; 62; 41].
Broader de nitions of fake news focus on the either
authenticity or intent of the news content. Some papers regard
satire news as fake news since the contents are false even
though satire is often entertainment-oriented and reveals its
own deceptiveness to the consumers [67; 4; 37; 9]. Other
literature directly treats deceptive news as fake news [
        <xref ref-type="bibr" rid="ref67">66</xref>
        ],
which includes serious fabrications, hoaxes, and satires.
In this article, we use the narrow de nition of fake news.
Formally, we state this de nition as follows,
Definition 1 (Fake News) Fake news is a news article
that is intentionally and veri ably false.
7http://www.politico.com/magazine/story/2016/12/fakenews-history-long-violent-214535
The reasons for choosing this narrow de nition are
threefolds. First, the underlying intent of fake news provides both
theoretical and practical value that enables a deeper
understanding and analysis of this topic. Second, any techniques
for truth veri cation that apply to the narrow conception
of fake news can also be applied to under the broader de
nition. Third, this de nition is able to eliminate the
ambiguities between fake news and related concepts that are not
considered in this article. The following concepts are not
fake news according to our de nition: (1) satire news with
proper context, which has no intent to mislead or deceive
consumers and is unlikely to be mis-perceived as factual;
(2) rumors that did not originate from news events; (3)
conspiracy theories, which are di cult verify as true or false;
(4) misinformation that is created unintentionally; and (5)
hoaxes that are only motivated by fun or to scam targeted
individuals.
2.2
      </p>
    </sec>
    <sec id="sec-5">
      <title>Fake News on Traditional News Media</title>
      <p>Fake news itself is not a new problem. The media ecology
of fake news has been changing over time from newsprint to
radio/television and, recently, online news and social media.
We denote \traditional fake news" as the fake news problem
before social media had important e ects on its production
and dissemination. Next, we will describe several
psychological and social science foundations that describe the impact
of fake news at both the individual and social information
ecosystem levels.</p>
      <sec id="sec-5-1">
        <title>Psychological Foundations of Fake News. Humans are</title>
        <p>
          naturally not very good at di erentiating between real and
fake news. There are several psychological and cognitive
theories that can explain this phenomenon and the in
uential power of fake news. Traditional fake news mainly
targets consumers by exploiting their individual vulnerabilities.
There are two major factors which make consumers
naturally vulnerable to fake news: (i) Nave Realism: consumers
tend to believe that their perceptions of reality are the only
accurate views, while others who disagree are regarded as
uninformed, irrational, or biased [
          <xref ref-type="bibr" rid="ref76">92</xref>
          ]; and (ii) Con rmation
Bias: consumers prefer to receive information that con rms
their existing views [
          <xref ref-type="bibr" rid="ref59">58</xref>
          ]. Due to these cognitive biases
inherent in human nature, fake news can often be perceived as real
by consumers. Moreover, once the misperception is formed,
it is very hard to correct it. Psychology studies shows that
correction of false information (e.g., fake news) by the
presentation of true, factual information is not only unhelpful
to reduce misperceptions, but sometimes may even increase
the misperceptions, especially among ideological groups [
          <xref ref-type="bibr" rid="ref60">59</xref>
          ].
        </p>
      </sec>
      <sec id="sec-5-2">
        <title>Social Foundations of the Fake News Ecosystem.</title>
        <p>Considering the entire news consumption ecosystem, we can
also describe some of the social dynamics that contribute to
the proliferation of fake news. Prospect theory describes
decision making as a process by which people make choices
based on the relative gains and losses as compared to their
current state [39; 81]. This desire for maximizing the reward
of a decision applies to social gains as well, for instance,
continued acceptance by others in a user's immediate social
network. As described by social identity theory [76; 77] and
normative in uence theory [3; 40], this preference for social
acceptance and a rmation is essential to a person's identity
and self-esteem, making users likely to choose \socially safe"
options when consuming and disseminating news
information, following the norms established in the community even
if the news being shared is fake news.</p>
        <p>
          This rational theory of fake news interactions can be
modeled from an economic game theoretical perspective [
          <xref ref-type="bibr" rid="ref26">26</xref>
          ] by
formulating the news generation and consumption cycle as a
two-player strategy game. For explaining fake news, we
assume there are two kinds of key players in the information
ecosystem: publisher and consumer. The process of news
publishing is modeled as a mapping from original signal s
to resultant news report a with an e ect of distortion bias
b, i.e., s !b a, where b = [ 1; 0; 1] indicates [lef t; no; right]
biases take e ects on news publishing process. Intuitively,
this is capturing the degree to which a news article may be
biased or distorted to produce fake news. The utility for
the publisher stems from two perspectives: (i) short-term
utility: the incentive to maximize pro t, which is positively
correlated with the number of consumers reached; (ii)
longterm utility: their reputation in terms of news authenticity.
Utility of consumers consists of two parts: (i) information
utility: obtaining true and unbiased information (usually
extra investment cost needed); (ii) psychology utility : receiving
news that satis es their prior opinions and social needs, e.g.,
con rmation bias and prospect theory. Both publisher and
consumer try to maximize their overall utilities in this
strategy game of the news consumption process. We can capture
the fact that fake news happens when the short-term utility
dominates a publisher's overall utility and psychology utility
dominates the consumer's overall utility, and an equilibrium
is maintained. This explains the social dynamics that lead
to an information ecosystem where fake news can thrive.
2.3
        </p>
      </sec>
    </sec>
    <sec id="sec-6">
      <title>Fake News on Social Media</title>
      <p>In this subsection, we will discuss some unique
characteristics of fake news on social media. Speci cally, we will
highlight the key features of fake news that are enabled by
social media. Note that the aforementioned characteristics
of traditional fake news are also applicable to social media.</p>
      <sec id="sec-6-1">
        <title>Malicious Accounts on Social Media for Propaganda.</title>
        <p>
          While many users on social media are legitimate, social
media users may also be malicious, and in some cases are not
even real humans. The low cost of creating social media
accounts also encourages malicious user accounts, such as
social bots, cyborg users, and trolls. A social bot refers to
a social media account that is controlled by a computer
algorithm to automatically produce content and interact with
humans (or other bot users) on social media [
          <xref ref-type="bibr" rid="ref23">23</xref>
          ]. Social bots
can become malicious entities designed speci cally with the
purpose to do harm, such as manipulating and spreading
fake news on social media. Studies shows that social bots
distorted the 2016 U.S. presidential election online
discussions on a large scale [
          <xref ref-type="bibr" rid="ref6">6</xref>
          ], and that around 19 million bot
accounts tweeted in support of either Trump or Clinton in
the week leading up to election day8. Trolls, real human
users who aim to disrupt online communities and provoke
consumers into an emotional response, are also playing an
important role in spreading fake news on social media. For
example, evidence suggests that there were 1,000 paid
Russian trolls spreading fake news on Hillary Clinton9. Trolling
behaviors are highly a ected by people's mood and the
context of online discussions, which enables the easy
dissemination of fake news among otherwise \normal" online
communities [
          <xref ref-type="bibr" rid="ref14">14</xref>
          ]. The e ect of trolling is to trigger people's
inner negative emotions, such as anger and fear, resulting
in doubt, distrust, and irrational behavior. Finally, cyborg
users can spread fake news in a way that blends automated
activities with human input. Usually cyborg accounts are
registered by human as a camou age and set automated
programs to perform activities in social media. The easy switch
of functionalities between human and bot o ers cyborg users
unique opportunities to spread fake news [
          <xref ref-type="bibr" rid="ref15">15</xref>
          ]. In a nutshell,
these highly active and partisan malicious accounts on
social media become the powerful sources and proliferation of
fake news.
        </p>
        <p>
          Echo Chamber E ect. Social media provides a new paradigm
of information creation and consumption for users. The
information seeking and consumption process are
changing from a mediated form (e.g., by journalists) to a more
disinter-mediated way [
          <xref ref-type="bibr" rid="ref19">19</xref>
          ]. Consumers are selectively
exposed to certain kinds of news because of the way news
feed appear on their homepage in social media, amplifying
the psychological challenges to dispelling fake news
identied above. For example, users on Facebook always follow
like-minded people and thus receive news that promote their
favored existing narratives [
          <xref ref-type="bibr" rid="ref66">65</xref>
          ]. Therefore, users on social
media tend to form groups containing like-minded people
where they then polarize their opinions, resulting in an echo
chamber e ect. The echo chamber e ect facilitates the
pro8http://comprop.oii.ox.ac.uk/2016/11/18/resource-forunderstanding-political-bots/
9http://www.hu
ngtonpost.com/entry/russian-trolls-fakenews us 58dde6bae4b08194e3b8d5c4
cess by which people consume and believe fake news due to
the following psychological factors [
          <xref ref-type="bibr" rid="ref61">60</xref>
          ]: (1) social credibility,
which means people are more likely to perceive a source as
credible if others perceive the source is credible, especially
when there is not enough information available to access the
truthfulness of the source; and (2) frequency heuristic, which
means that consumers may naturally favor information they
hear frequently, even if it is fake news. Studies have shown
that increased exposure to an idea is enough to generate a
positive opinion of it [100; 101], and in echo chambers, users
continue to share and consume the same information. As a
result, this echo chamber e ect creates segmented,
homogeneous communities with a very limited information
ecosystem. Research shows that the homogeneous communities
become the primary driver of information di usion that
further strengthens polarization [
          <xref ref-type="bibr" rid="ref18">18</xref>
          ].
3.
        </p>
      </sec>
    </sec>
    <sec id="sec-7">
      <title>FAKE NEWS DETECTION</title>
      <p>In the previous section, we introduced the conceptual
characterization of traditional fake news and fake news in
social media. Based on this characterization, we further
explore the problem de nition and proposed approaches for
fake news detection.
3.1</p>
    </sec>
    <sec id="sec-8">
      <title>Problem Definition</title>
      <p>In this subsection, we present the details of mathematical
formulation of fake news detection on social media.
Specifically, we will introduce the de nition of key components
of fake news and then present the formal de nition of fake
news detection. The basic notations are de ned below,
Let a refer to a News Article. It consists of two
major components: Publisher and Content. Publisher p~a
includes a set of pro le features to describe the
original author, such as name, domain, age, among other
attributes. Content c~a consists of a set of attributes
that represent the news article and includes headline,
text, image, etc.</p>
      <p>We also de ne Social News Engagements as a set of
tuples E = feitg to represent the process of how news
spread over time among n users U = fu1; u2; :::; ung
and their corresponding posts P = fp1; p2; :::; png on
social media regarding news article a. Each
engagement eit = fui; pi; tg represents that a user ui spreads
news article a using pi at time t. Note that we set
t = N ull if the article a does not have any
engagement yet and thus ui represents the publisher.</p>
      <p>Definition 2 (Fake News Detection) Given the social
news engagements E among n users for news article a, the
task of fake news detection is to predict whether the news
article a is a fake news piece or not, i.e., F : E ! f0; 1g
such that,</p>
      <p>
        F (a) =
(1; if a is a piece of fake news,
0; otherwise.
(1)
where F is the prediction function we want to learn.
Note that we de ne fake news detection as a binary classi
cation problem for the following reason: fake news is
essentially a distortion bias on information manipulated by the
publisher. According to previous research about media bias
theory [
        <xref ref-type="bibr" rid="ref26">26</xref>
        ], distortion bias is usually modeled as a binary
classi cation problem.
      </p>
      <p>Next, we propose a general data mining framework for fake
news detection which includes two phases: (i) feature
extraction and (ii) model construction. The feature extraction
phase aims to represent news content and related auxiliary
information in a formal mathematical structure, and model
construction phase further builds machine learning models
to better di erentiate fake news and real news based on the
feature representations.
3.2</p>
    </sec>
    <sec id="sec-9">
      <title>Feature Extraction</title>
      <p>Fake news detection on traditional news media mainly relies
on news content, while in social media, extra social context
auxiliary information can be used to as additional
information to help detect fake news. Thus, we will present the
details of how to extract and represent useful features from
news content and social context.
3.2.1</p>
      <sec id="sec-9-1">
        <title>News Content Features</title>
        <p>News content features c~a describe the meta information
related to a piece of news. A list of representative news content
attributes are listed below:</p>
        <p>Source: Author or publisher of the news article
Headline: Short title text that aims to catch the
attention of readers and describes the main topic of the
article
Body Text: Main text that elaborates the details of
the news story; there is usually a major claim that is
speci cally highlighted and that shapes the angle of
the publisher
Image/Video: Part of the body content of a news
article that provides visual cues to frame the story
Based on these raw content attributes, di erent kinds of
feature representations can be built to extract discriminative
characteristics of fake news. Typically, the news content we
are looking at will mostly be linguistic-based and
visualbased, described in more detail below.</p>
        <p>
          Linguistic-based: Since fake news pieces are
intentionally created for nancial or political gain rather than to
report objective claims, they often contain opinionated and
in ammatory language, crafted as \clickbait" (i.e., to
entice users to click on the link to read the full article) or
to incite confusion [
          <xref ref-type="bibr" rid="ref13">13</xref>
          ]. Thus, it is reasonable to exploit
linguistic features that capture the di erent writing styles
and sensational headlines to detect fake news.
Linguisticbased features are extracted from the text content in terms
of document organizations from di erent levels, such as
characters, words, sentences, and documents. In order to
capture the di erent aspects of fake news and real news,
existing work utilized both common linguistic features and
domain-speci c linguistic features. Common linguistic
features are often used to represent documents for various tasks
in natural language processing. Typical common
linguistic features are: (i) lexical features, including
characterlevel and word-level features, such as total words,
characters per word, frequency of large words, and unique words;
(ii) syntactic features, including sentence-level features, such
as frequency of function words and phrases (i.e., \n-grams"
and bag-of-words approaches [
          <xref ref-type="bibr" rid="ref24">24</xref>
          ]) or punctuation and
partsof-speech (POS) tagging. Domain-speci c linguistic
features, which are speci cally aligned to news domain, such
as quoted words, external links, number of graphs, and the
average length of graphs, etc [
          <xref ref-type="bibr" rid="ref63">62</xref>
          ]. Moreover, other features
can be speci cally designed to capture the deceptive cues
in writing styles to di erentiate fake news, such as
lyingdetection features [
          <xref ref-type="bibr" rid="ref1">1</xref>
          ].
        </p>
        <p>
          Visual-based: Visual cues have been shown to be an
important manipulator for fake news propaganda10. As we
have characterized, fake news exploits the individual
vulnerabilities of people and thus often relies on sensational or even
fake images to provoke anger or other emotional response of
consumers. Visual-based features are extracted from visual
elements (e.g. images and videos) to capture the di erent
characteristics for fake news. Faking images were identi ed
based on various user-level and tweet-level hand-crafted
features using classi cation framework [
          <xref ref-type="bibr" rid="ref28">28</xref>
          ]. Recently, various
visual and statistical features has been extracted for news
veri cation [
          <xref ref-type="bibr" rid="ref38">38</xref>
          ]. Visual features include clarity score,
coherence score, similarity distribution histogram, diversity score,
and clustering score. Statistical features include count,
image ratio, multi-image ratio, hot image ratio, long image
ratio, etc.
3.2.2
        </p>
      </sec>
      <sec id="sec-9-2">
        <title>Social Context Features</title>
        <p>In addition to features related directly to the content of
the news articles, additional social context features can also
be derived from the user-driven social engagements of news
consumption on social media platform. Social engagements
represent the news proliferation process over time, which
provides useful auxiliary information to infer the veracity of
news articles. Note that few papers exist in the literature
that detect fake news using social context features.
However, because we believe this is a critical aspect of successful
fake news detection, we introduce a set of common features
utilized in similar research areas, such as rumor veracity
classi cation on social media. Generally, there are three
major aspects of the social media context that we want to
represent: users, generated posts, and networks. Below, we
investigate how we can extract and represent social context
features from these three aspects to support fake news
detection.</p>
        <p>
          User-based: As we mentioned in Section 2.3, fake news
pieces are likely to be created and spread by non-human
accounts, such as social bots or cyborgs. Thus, capturing
users' pro les and characteristics by user-based features can
provide useful information for fake news detection.
Userbased features represent the characteristics of those users
who have interactions with the news on social media. These
features can be categorized across di erent levels: individual
level and group level. Individual level features are extracted
to infer the credibility and reliability for each user using
various aspects of user demographics, such as registration
age, number of followers/followees, number of tweets the
user has authored, etc [
          <xref ref-type="bibr" rid="ref11">11</xref>
          ]. Group level user features
capture overall characteristics of groups of users related to the
news [
          <xref ref-type="bibr" rid="ref83">99</xref>
          ]. The assumption is that the spreaders of fake news
10https://www.wired.com/2016/12/photos-fuel-spread-fakenews/
and real news may form di erent communities with unique
characteristics that can be depicted by group level features.
Commonly used group level features come from
aggregating (e.g., averaging and weighting) individual level features,
such as `percentage of veri ed users' and `average number
of followers' [49; 42].
        </p>
        <p>
          Post-based: People express their emotions or opinions
towards fake news through social media posts, such as
skeptical opinions, sensational reactions, etc. Thus, it is
reasonable to extract post-based features to help nd potential
fake news via reactions from the general public as expressed
in posts. Post-based features focus on identifying useful
information to infer the veracity of news from various aspects
of relevant social media posts. These features can be
categorized as post level, group level, and temporal level. Post
level features generate feature values for each post. The
aforementioned linguistic-based features and some
embedding approaches [
          <xref ref-type="bibr" rid="ref70">69</xref>
          ] for news content can also be applied
for each post. Speci cally, there are unique features for
posts that represent the social response from general
public, such as stance, topic, and credibility. Stance features (or
viewpoints) indicate the users' opinions towards the news,
such as supporting, denying, etc [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ]. Topic features can be
extracted using topic models, such as latent Dirichlet
allocation (LDA) [
          <xref ref-type="bibr" rid="ref49">49</xref>
          ]. Credibility features for posts assess the
degree of reliability [
          <xref ref-type="bibr" rid="ref11">11</xref>
          ]. Group level features aim to
aggregate the feature values for all relevant posts for speci c
news articles by using \wisdom of crowds". For example,
the average credibility scores are used to evaluate the
credibility of news [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ]. A more comprehensive list of group-level
post features can also be found in [
          <xref ref-type="bibr" rid="ref11">11</xref>
          ]. Temporal level
features consider the temporal variations of post level feature
values [
          <xref ref-type="bibr" rid="ref49">49</xref>
          ]. Unsupervised embedding methods, such as
recurrent neural network (RNN), are utilized to capture the
changes in posts over time [69; 48]. Based on the shape of
this time series for various metrics of relevant posts (e.g,
number of posts), mathematical features can be computed,
such as SpikeM parameters [
          <xref ref-type="bibr" rid="ref42">42</xref>
          ].
        </p>
        <p>
          Network-based: Users form di erent networks on social
media in terms of interests, topics, and relations. As
mentioned before, fake news dissemination processes tend to
form an echo chamber cycle, highlighting the value of
extracting network-based features to represent these types of
network patterns for fake news detection. Network-based
features are extracted via constructing speci c networks among
the users who published related social media posts. Di erent
types of networks can be constructed. The stance network
can be built with nodes indicating all the tweets relevant
to the news and the edge indicating the weights of
similarity of stances [37; 75]. Another type of network is the
cooccurrence network, which is built based on the user
engagements by counting whether those users write posts relevant
to the same news articles [
          <xref ref-type="bibr" rid="ref70">69</xref>
          ]. In addition, the friendship
network indicates the following/followee structure of users
who post related tweets [
          <xref ref-type="bibr" rid="ref42">42</xref>
          ]. An extension of this friendship
network is the di usion network, which tracks the trajectory
of the spread of news [
          <xref ref-type="bibr" rid="ref42">42</xref>
          ], where nodes represent the users
and edges represent the information di usion paths among
them. That is, a di usion path between two users ui and uj
exists if and only if (1) uj follows ui, and (2) uj posts about
a given news only after ui does so. After these networks
are properly built, existing network metrics can be applied
as feature representations. For example, degree and
clustering coe cient have been used to characterize the di usion
network [
          <xref ref-type="bibr" rid="ref42">42</xref>
          ] and friendship network [
          <xref ref-type="bibr" rid="ref42">42</xref>
          ]. Other approaches
learn the latent node embedding features by using SVD [
          <xref ref-type="bibr" rid="ref70">69</xref>
          ]
or network propagation algorithms [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ].
3.3
        </p>
      </sec>
    </sec>
    <sec id="sec-10">
      <title>Model Construction</title>
      <p>In the previous section, we introduced features extracted
from di erent sources, i.e., news content and social
context, for fake news detection. In this section, we discuss the
details of the model construction process for several
existing approaches. Speci cally we categorize existing methods
based on their main input sources as: News Content Models
and Social Context Models.
3.3.1</p>
      <sec id="sec-10-1">
        <title>News Content Models</title>
        <p>In this subsection, we focus on news content models, which
mainly rely on news content features and existing factual
sources to classify fake news. Speci cally, existing approaches
can be categorized as Knowledge-based and Style-based.
Knowledge-based: Since fake news attempts to spread
false claims in news content, the most straightforward means
of detecting it is to check the truthfulness of major claims
in a news article to decide the news veracity.
Knowledgebased approaches aim to use external sources to fact-check
proposed claims in news content. The goal of fact-checking is
to assign a truth value to a claim in a particular context [83].
Fact-checking has attracted increasing attention, and many
e orts have been made to develop a feasible automated
factchecking system. Existing fact-checking approaches can be
categorized as expert-oriented, crowdsourcing-oriented, and
computational-oriented.</p>
        <p>Expert-oriented fact-checking heavily relies on human
domain experts to investigate relevant data and
documents to construct the verdicts of claim veracity, for
example PolitiFact11, Snopes12, etc. However,
expertoriented fact-checking is an intellectually demanding
and time-consuming process, which limits the
potential for high e ciency and scalability.</p>
        <p>Crowdsourcing-oriented fact-checking exploits the
\wisdom of crowd" to enable normal people to annotate
news content; these annotations are then aggregated
to produce an overall assessment of the news
veracity. For example, Fiskkit13 allows users to discuss and
annotate the accuracy of speci c parts of a news
article. As another example, an anti-fake news bot named
\For real" is a public account in the instant
communication mobile application LINE14, which allows people
to report suspicious news content which is then further
checked by editors.</p>
        <p>
          Computational-oriented fact-checking aims to provide
an automatic scalable system to classify true and false
claims. Previous computational-oriented fact checking
methods try to solve two majors issues: (i) identifying
11http://www.politifact.com/
12http://www.snopes.com/
13http:// skkit.com
14https://grants.g0v.tw/projects/588fa7b382223f001e022944
check-worthy claims and (ii) discriminating the
veracity of fact claims. To identify check-worthy claims,
factual claims in news content are extracted that convey
key statements and viewpoints, facilitating the
subsequent fact-checking process [
          <xref ref-type="bibr" rid="ref31">31</xref>
          ]. Fact-checking for
speci c claims largely relies on external resources to
determine the truthfulness of a particular claim. Two
typical external sources include the open web and
structured knowledge graph. Open web sources are utilized
as references that can be compared with given claims
in terms of both the consistency and frequency [5; 50].
Knowledge graphs are integrated from the linked open
data as a structured network topology, such as
DBpedia and Google Relation Extraction Corpus.
Factchecking using a knowledge graph aims to check whether
the claims in news content can be inferred from
existing facts in the knowledge graph [98; 16; 72].
        </p>
        <p>Style-based: Fake news publishers often have malicious
intent to spread distorted and misleading information and
in uence large communities of consumers, requiring
particular writing styles necessary to appeal to and persuade a
wide scope of consumers that is not seen in true news
articles. Style-based approaches try to detect fake news by
capturing the manipulators in the writing style of news
content. There are mainly two typical categories of style-based
methods: Deception-oriented and Objectivity-oriented.</p>
        <p>
          Deception-oriented stylometric methods capture the
deceptive statements or claims from news content. The
motivation of deception detection originates from
forensic psychology (i.e., Undeutsch Hypothesis) [82] and
various forensic tools including Criteria-based Content
Analysis [84] and Scienti c-based Content Analysis [
          <xref ref-type="bibr" rid="ref45">45</xref>
          ]
have been developed. More recently, advanced
natural language processing models are applied to spot
deception phases from the following perspectives: Deep
syntax and Rhetorical structure. Deep syntax models
have been implemented using probabilistic context
frree grammers (PCFG), with which sentences can be
transformed into rules that describe the syntax
structure. Based on the PCFG, di erent rules can be
developed for deception detection, such as unlexicalized/
lexicalized production rules and grandparent rules [
          <xref ref-type="bibr" rid="ref22">22</xref>
          ].
Rhetorical structure theory can be utilized to capture
the di erences between deceptive and truthful
sentences [
          <xref ref-type="bibr" rid="ref69">68</xref>
          ]. Deep network models, such as
convolutional neural networks (CNN), have also been applied
to classify fake news veracity [
          <xref ref-type="bibr" rid="ref74">90</xref>
          ].
        </p>
        <p>
          Objectivity-oriented approaches capture style signals
that can indicate a decreased objectivity of news
content and thus the potential to mislead consumers, such
as hyperpartisan styles and yellow-journalism.
Hyperpartisan styles represent extreme behavior in favor of a
particular political party, which often correlates with
a strong motivation to create fake news.
Linguisticbased features can be applied to detect hyperpartisan
articles [
          <xref ref-type="bibr" rid="ref63">62</xref>
          ]. Yellow-journalism represents those
articles that do not contain well-researched news, but
instead rely on eye-catching headlines (i.e., clickbait)
with a propensity for exaggeration, sensationalization,
scare-mongering, etc. Often, news titles will
summarize the major viewpoints of the article that the author
wants to convey, and thus misleading and deceptive
clickbait titles can serve as a good indicator for
recognizing fake news articles [
          <xref ref-type="bibr" rid="ref13">13</xref>
          ].
3.3.2
        </p>
      </sec>
      <sec id="sec-10-2">
        <title>Social Context Models</title>
        <p>The nature of social media provides researchers with
additional resources to supplement and enhance News
Content Models. Social context models include relevant user
social engagements in the analysis, capturing this auxiliary
information from a variety of perspectives. We can
classify existing approaches for social context modeling into two
categories: Stance-based and Propagation-based. Note that
very few existing fake news detection approaches have
utilized social context models. Thus, we also introduce similar
methods for rumor detection using social media, which have
potential application for fake news detection.</p>
        <p>
          Stance-based: Stance-based approaches utilize users'
viewpoints from relevant post contents to infer the veracity of
original news articles. The stance of users' posts can be
represented either explicitly or implicitly. Explicit stances
are direct expressions of emotion or opinion, such as the
\thumbs up" and \thumbs down" reactions expressed in
Facebook. Implicit stances can be automatically extracted
from social media posts. Stance detection is the task of
automatically determining from a post whether the user is
in favor of, neutral toward, or against some target entity,
event, or idea [
          <xref ref-type="bibr" rid="ref53">53</xref>
          ]. Previous stance classi cation methods
mainly rely on hand-crafted linguistic or embedding features
on individual posts to predict stances [53; 64]. Topic model
methods, such as latent dirichlet allocation (LDA) can be
applied to learn latent stance from topics [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ]. Using these
methods, we can infer the news veracity based on the stance
values of relevant posts. Tacchini et al. proposed to
construct a bipartite network of user and Facebook posts using
the \like" stance information [75]; based on this network,
a semi-supervised probabilistic model was used to predict
the likelihood of Facebook posts being hoaxes. Jin et al.
explored topic models to learn latent viewpoint values and
further exploited these viewpoints to learn the credibility of
relevant posts and news content [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ].
        </p>
        <p>
          Propagation-based: Propagation-based approaches for fake
news detection reason about the interrelations of relevant
social media posts to predict news credibility. The basic
assumption is that the credibility of a news event is highly
related to the credibilities of relevant social media posts.
Both homogeneous and heterogeneous credibility networks
can be built for propagation process. Homogeneous
credibility networks consist of a single type of entities, such as
post or event [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ]. Heterogeneous credibility networks
involve di erent types of entities, such as posts, sub-events,
and events [36; 29]. Gupta et al. proposed a PageRank-like
credibility propagation algorithm by encoding users'
credibilities and tweets' implications on a three layer
user-tweetevent heterogeneous information network. Jin et al.
proposed to include news aspects (i.e., latent sub-events), build
a three-layer hierarchical network, and utilize a graph
optimization framework to infer event credibilities. Recently,
the con icting viewpoint relationships are included to build
a homogeneous credibility network among tweets and guide
the process to evaluate their credibilities [
          <xref ref-type="bibr" rid="ref37">37</xref>
          ].
        </p>
      </sec>
    </sec>
    <sec id="sec-11">
      <title>ASSESSING DETECTION EFFICACY</title>
      <p>In this section, we discuss how to assess the performance of
algorithms for fake news detection. We focus on the
available datasets and evaluation metrics for this task.
4.1</p>
    </sec>
    <sec id="sec-12">
      <title>Datasets</title>
      <p>Online news can be collected from di erent sources, such
as news agency homepages, search engines, and social
media websites. However, manually determining the
veracity of news is a challenging task, usually requiring
annotators with domain expertise who performs careful analysis of
claims and additional evidence, context, and reports from
authoritative sources. Generally, news data with
annotations can be gathered in the following ways: Expert
journalists, Fact-checking websites, Industry detectors, and
Crowdsourced workers. However, there are no agreed upon
benchmark datasets for the fake news detection problem. Some
publicly available datasets are listed below:</p>
      <p>
        BuzzFeedNews15: This dataset comprises a complete
sample of news published in Facebook from 9 news
agencies over a week close to the 2016 U.S. election
from September 19 to 23 and September 26 and 27.
Every post and the linked article were fact-checked
claim-by-claim by 5 BuzzFeed journalists. This dataset
is further enriched in [
        <xref ref-type="bibr" rid="ref63">62</xref>
        ] by adding the linked articles,
attached media, and relevant metadata. It contains
1,627 articles{826 mainstream, 356 left-wing, and 545
right-wing articles.
      </p>
      <p>
        LIAR16: This dataset is collected from fact-checking
website PolitiFact through its API [
        <xref ref-type="bibr" rid="ref74">90</xref>
        ]. It includes
12,836 human-labeled short statements, which are
sampled from various contexts, such as news releases, TV
or radio interviews, campaign speeches, etc. The labels
for news truthfulness are ne-grained multiple classes:
pants- re, false, barely-true, half-true, mostly true,
and true.
      </p>
      <p>BS Detector 17: This dataset is collected from a browser
extension called BS detector developed for checking
news veracity18. It searches all links on a given
webpage for references to unreliable sources by checking
against a manually complied list of domains. The
labels are the outputs of BS detector, rather than human
annotators.</p>
      <p>
        CREDBANK 19: This is a large scale crowdsourced
dataset of approximately 60 million tweets that cover
96 days starting from October 2015. All the tweets are
broken down to be related to over 1,000 news events,
with each event assessed for credibilities by 30
annotators from Amazon Mechanical Turk [
        <xref ref-type="bibr" rid="ref52">52</xref>
        ].
      </p>
      <p>In Table 1, we compare these public fake news detection
datasets, highlighting the features that can be extracted
from each dataset. We can see that no existing public dataset
can provide all possible features of interest. In addition,
15https://github.com/BuzzFeedNews/2016-10-facebookfact-check/tree/master/data
16https://www.cs.ucsb.edu/ william/data/liar dataset.zip
17https://www.kaggle.com/mrisdal/fake-news
18https://github.com/bs-detector/bs-detector
19http://compsocial.github.io/CREDBANK-data/
these datasets also have speci c limitation that make them
challenging to use for fake news detection. BuzzFeedNews
only contains headlines and text for each news piece and
covers news articles from very few news agencies. LIAR
includes mostly short statements, rather than the entire news
content. Further, these statements are collected from
various speakers, rather than news publishers, and may include
some claims that are not fake news. BS Detector data is
collected and annotated by using a developed news veracity
checking tool. As the labels have not been properly
validated by human experts, any model trained on this data is
really learning the parameters of BS Detector, rather than
expert-annotated ground truth fake news. Finally,
CREDBANK was originally collected for tweet credibility
assessment, so the tweets in this dataset are not really the social
engagements for speci c news articles.</p>
      <p>To address the disadvantages of existing fake news
detection datasets, we have an ongoing project to develop a
usable dataset for fake news detection on social media. This
dataset, called F akeN ewsN et20, includes all mentioned news
content and social context features with reliable ground truth
fake news labels.
4.2</p>
    </sec>
    <sec id="sec-13">
      <title>Evaluation Metrics</title>
      <p>To evaluate the performance of algorithms for fake news
detection problem, various evaluation metrics have been used.
In this subsection, we review the most widely used metrics
for fake news detection. Most existing approaches consider
the fake news problem as a classi cation problem that
predicts whether a news article is fake or not:</p>
      <p>True Positive (TP): when predicted fake news pieces
are actually annotated as fake news;
True Negative (TN): when predicted true news pieces
are actually annotated as true news;
False Negative (FN): when predicted true news pieces
are actually annotated as fake news;
False Positive (FP): when predicted fake news pieces
are actually annotated as true news.</p>
      <p>By formulating this as a classi cation problem, we can de ne
following metrics,</p>
      <p>P recision</p>
      <p>=</p>
      <p>Recall =
Accuracy</p>
      <p>=
F 1 = 2</p>
      <p>jT P j
jT P j + jF P j</p>
      <p>jT P j
jT P j + jF N j</p>
      <p>P recision Recall
P recision + Recall</p>
      <p>jT P j + jT N j
jT P j + jT N j + jF P j + jF N j
(2)
(3)
(4)
(5)
These metrics are commonly used in the machine learning
community and enable us to evaluate the performance of a
classi er from di erent perspectives. Speci cally, accuracy
measures the similarity between predicted fake news and real
fake news. Precision measures the fraction of all detected
fake news that are annotated as fake news, addressing the
important problem of identifying which news is fake.
However, because fake news datasets are often skewed, a high
precision can be easily achieved by making fewer positive
20https://github.com/KaiDMML/FakeNewsNet
Dataset</p>
      <sec id="sec-13-1">
        <title>BuzzFeedNews</title>
      </sec>
      <sec id="sec-13-2">
        <title>LIAR</title>
      </sec>
      <sec id="sec-13-3">
        <title>BS Detector</title>
      </sec>
      <sec id="sec-13-4">
        <title>CREDBANK</title>
        <p>predictions. Thus, recall is used to measure the sensitivity,
or the fraction of annotated fake news articles that are
predicted to be fake news. F1 is used to combine precision and
recall, which can provide an overall prediction performance
for fake news detection. Note that for P recision; Recall,
F1, and Accuracy, the higher the value, the better the
performance.</p>
        <p>The Receiver Operating Characteristics (ROC) curve
provides a way of comparing the performance of classi ers by
looking at the trade-o in the False Positive Rate (FPR) and
the True Positive Rate (TPR). To draw the ROC curve, we
plot the FPR on the x axis and and TPR along the y axis.
The ROC curve compares the performance of di erent
classi ers by changing class distributions via a threshold. TPR
and FPR are de ned as follows (note that TPR is the same
as recall de ned above):</p>
        <p>T P R
F P R
=
=</p>
        <p>jT P j
jT P j + jF N j</p>
        <p>
          jF P j
jF P j + jT N j
Based on the ROC curve, we can compute the Area Under
the Curve (AUC) value, which measures the overall
performance of how likely the classi er is to rank the fake news
higher than any true news. Based on [
          <xref ref-type="bibr" rid="ref30">30</xref>
          ], AUC is de ned
as below.
        </p>
        <p>AU C =</p>
        <p>P(n0 + n1 + 1</p>
        <p>
          ri)
n0n1
n0(n0 + 1)=2
where ri is the rank of ith fake news piece and n0 (n1) is
the number of fake (true) news pieces. It is worth
mentioning that AUC is more statistically consistent and more
discriminating than accuracy [
          <xref ref-type="bibr" rid="ref47">47</xref>
          ], and it is usually applied
in an imbalanced classi cation problem, such as fake news
classi cation, where the number of ground truth fake news
articles and and true news articles have a very imbalanced
distribution.
        </p>
      </sec>
    </sec>
    <sec id="sec-14">
      <title>RELATED AREAS</title>
      <p>In this section, we further discuss areas that are related to
the problem of fake news detection. We aim to point out
the di erences between these areas and fake news detection
by brie y explaining the task goals and highlighting some
popular methods.
5.1</p>
    </sec>
    <sec id="sec-15">
      <title>Rumor Classification</title>
      <p>
        A rumor can usually be de ned as \a piece of circulating
information whose veracity status is yet to be veri ed at
the time of spreading" [
        <xref ref-type="bibr" rid="ref86">102</xref>
        ]. The function of a rumor is
to make sense of an ambiguous situation, and the
truthfulness value could be true, false or unveri ed. Previous
approaches for rumor analysis focus on four subtasks: rumor
X
X
X
X
(6)
(7)
(8)
detection, rumor tracking, stance classi cation, and
veracity classi cation [
        <xref ref-type="bibr" rid="ref86">102</xref>
        ]. Speci cally, rumor detection aims to
classify a piece of information as rumor or non-rumor [96;
70]; rumor tracking aims to collect and lter posts discussing
speci c rumors; rumor stance classi cation determines how
each relevant post is oriented with respect to the rumor's
veracity; veracity classi cation attempts to predict the
actual truth value of the rumor. The most related task to fake
news detection is the rumor veracity classi cation. Rumor
veracity classi cation relies heavily on the other subtasks,
requiring the stances or opinions can be extracted from
relevant posts. These posts are considered as important
sensors for determining the veracity of the rumor. Di erent
from rumors, which may include long-term rumors, such as
conspiracy theories, as well as short-term emerging rumors,
fake news refers to information related speci cally to public
news events that can be veri ed as false.
5.2
      </p>
    </sec>
    <sec id="sec-16">
      <title>Truth Discovery</title>
      <p>
        Truth discovery is the problem of detecting true facts from
multiple con icting sources [
        <xref ref-type="bibr" rid="ref46">46</xref>
        ]. Truth discovery methods
do not explore the fact claims directly, but rely on a
collection of contradicting sources that record the properties of
objects to determine the truth value. Truth discovery aims
to determine the source credibility and object truthfulness
at the same time. The fake news detection problem can
bene t from various aspects of truth discovery approaches
under di erent scenarios. First, the credibility of di erent
news outlets can be modeled to infer the truthfulness of
reported news. Second, relevant social media posts can also
be modeled as social response sources to better determine
the truthfulness of claims [56; 93]. However, there are some
other issues that must be considered to apply truth discovery
to fake news detection in social media scenarios. First, most
existing truth discovery methods focus on handling
structured input in the form of Subject-Predicate-Object (SPO)
tuples, while social media data is highly unstructured and
noisy. Second, truth discovery methods can not be well
applied when a fake news article is newly launched and
published by only a few news outlets because at that point there
is not enough social media posts relevant to it to serve as
additional sources.
5.3
      </p>
    </sec>
    <sec id="sec-17">
      <title>Clickbait Detection</title>
      <p>
        Clickbait is a term commonly used to describe eye-catching
and teaser headlines in online media. Clickbait headlines
create a so-called \curiosity gap", increasing the likelihood
that reader will click the target link to satisfy their
curiosity. Existing clickbait detection approaches utilize various
linguistic features extracted from teaser messages, linked
webpages, and tweet meta information [12; 8; 63]. Di
erent types of clickbait are categorized, and some of them are
highly correlated with non-factual claims [
        <xref ref-type="bibr" rid="ref7">7</xref>
        ]. The
underlying motivation of clickbait is usually for click-through rates
and the resultant advertising revenue. Thus, the body text
of clickbait articles are often informally organized and poorly
reasoned. This discrepancy has been used by researchers to
identify the inconsistency between headlines and news
contents in an attempt to detect fake news articles21. Even
though not all fake news may include clickbait headlines,
speci c clickbait headlines could serve as an important
indicator, and various features can be utilized to help detect
fake news.
5.4
      </p>
    </sec>
    <sec id="sec-18">
      <title>Spammer and Bot Detection</title>
      <p>
        Spammer detection on social media, which aims to
capture malicious users that coordinate among themselves to
launch various attacks, such as spreading ads,
disseminating pornography, delivering viruses, and phishing [
        <xref ref-type="bibr" rid="ref44">44</xref>
        ], has
recently attracted wide attention. Existing approaches for
social spammer detection mainly rely on extracting features
from user activities and social network information [35; 95;
33; 34]. In addition, the rise of social bots has also increased
the circulation of false information as they automatically
retweet posts without verifying the facts [
        <xref ref-type="bibr" rid="ref23">23</xref>
        ]. The major
challenge brought by social bots is that they can give a false
impression that information is highly popular and endorsed
by many people, which enables the echo chamber e ect for
the propagation of fake news. Previous approaches for bot
detection are based on social network information,
crowdsourcing, and discriminative features [23; 55; 54]. Thus,
both spammer and social bots could provide insights about
target speci c malicious social media accounts that can be
used for fake news detection.
      </p>
    </sec>
    <sec id="sec-19">
      <title>OPEN ISSUES AND FUTURE RESEARCH</title>
      <p>In this section, we present some open issues in fake news
detection and future research directions. Fake news
detection on social media is a newly emerging research area, so
we aim to point out promising research directions from a
data mining perspective. Speci cally, as shown in Figure 2,
we outline the research directions in four categories:
Dataoriented, Feature-oriented, Model-oriented and
Applicationoriented.</p>
      <p>
        Data-oriented: Data-oriented fake news research is
focusing on di erent kinds of data characteristics, such as :
dataset, temporal and psychological. From a dataset
perspective, we demonstrated that there is no existing
benchmark dataset that includes resources to extract all relevant
features. A promising direction is to create a comprehensive
and large-scale fake news benchmark dataset, which can be
used by researchers to facilitate further research in this area.
From a temporal perspective, fake news dissemination on
social media demonstrates unique temporal patterns di erent
from true news. Along this line, one interesting problem
is to perform early fake news detection, which aims to give
early alerts of fake news during the dissemination process.
For example, this approach could look at only social media
posts within some time delay of the original post as sources
for news veri cation [
        <xref ref-type="bibr" rid="ref37">37</xref>
        ]. Detecting fake news early can help
prevent further propagation on social media. From a
psychological perspective, di erent aspects of fake news have been
qualitatively explored in the social psychology literature [92;
21http://www.fakenewschallenge.org/
58; 59], but quantitative studies to verify these psychological
factors are rather limited. For example, the echo chamber
e ect plays an important role for fake news spreading in
social media. Then how to capture echo chamber e ects and
how to utilize the pattern for fake news detection in social
media could be an interesting investigation. Moreover,
intention detection from news data is promising but limited
as most existing fake news research focus on detecting the
authenticity but ignore the intent aspect of fake news.
Intention detection is very challenging as the intention is often
explicitly unavailable. Thus. it's worth to explore how to
use data mining methods to validate and capture
psychology intentions.
      </p>
      <p>
        Feature-oriented: Feature-oriented fake news research aims
to determine e ective features for detecting fake news from
multiple data sources. We have demonstrated that there are
two major data sources: news content and social context.
From a news content perspective, we introduced
linguisticbased and visual-based techniques to extract features from
text information. Note that linguistic-based features have
been widely studied for general NLP tasks, such as text
classi cation and clustering, and speci c applications such as
author identi cation [
        <xref ref-type="bibr" rid="ref32">32</xref>
        ] and deception detection [
        <xref ref-type="bibr" rid="ref22">22</xref>
        ], but
the underlying characteristics of fake news have not been
fully understood. Moreover, embedding techniques, such as
word embedding and deep neural networks, are attracting
much attention for textual feature extraction, and has the
potential to learn better representations [90; 87; 88]. In
addition, visual features extracted from images are also shown
to be important indicators for fake news [
        <xref ref-type="bibr" rid="ref38">38</xref>
        ]. However, very
limited research has been done to exploit e ective visual
features, including traditional local and global features [
        <xref ref-type="bibr" rid="ref62">61</xref>
        ] and
newly emerging deep network-based features [43; 89; 85],
for the fake news detection problem. Recently, it has been
shown that advanced tools can manipulate video footage of
public gures [80], synthesize high quality videos [74], etc.
Thus, it becomes much more challenging and important to
di erentiate real and fake visual content, and more advanced
visual-based features are needed for this research. From a
social context perspective, we introduced user-based,
postbased, and network-based features. Existing user-based
features mainly focus on general user pro les, rather than
differentiating account types separately and extracting
userspeci c features. Post-based features can be represented
using other techniques, such as convolutional neural networks
(CNN) [
        <xref ref-type="bibr" rid="ref70">69</xref>
        ], to better capture people's opinions and
reactions toward fake news. Images in social media posts can
also be utilized to better understand users' sentiments [
        <xref ref-type="bibr" rid="ref75">91</xref>
        ]
toward news events. Network-based features are extracted
to represent how di erent types of networks are constructed.
It is important to extend this preliminary work to explore
(i) how other networks can be constructed in terms of di
erent aspects of relationships among relevant users and posts;
and (ii) other advanced methods of network representations,
such as network embedding [78; 86].
      </p>
      <p>
        Model-oriented: Model-oriented fake news research opens
the door to building more e ective and practical models for
fake news detection. Most previously mentioned approaches
focus on extracting various features, incorporating theses
features into supervised classi cation models, such as nave
Bayes, decision tree, logistic regression, k nearest neighbor
(KNN), and support vector machines (SVM), and then
selecting the classi er that performs the best [62; 75; 1]. More
research can be done to build more complex and e ective
models and to better utilize extracted features, such as
aggregation methods, probabilistic methods, ensemble methods,
or projection methods [73]. Speci cally, we think there is
some promising research in the following directions. First,
aggregation methods combine di erent feature
representations into a weighted form and optimize the feature weights.
Second, since fake news may commonly mix true statements
with false claims, it may make more sense to predict the
likelihood of fake news instead of producing a binary value;
probabilistic models predict a probabilistic distribution of
class labels (i.e., fake news versus true news) by assuming
a generative model that pulls from the same distribution as
the original feature space [
        <xref ref-type="bibr" rid="ref25">25</xref>
        ]. Third, one of the major
challenges for fake news detection is the fact that each feature,
such as source credibility, news content style, or social
response, has some limitations to directly predict fake news on
its own. Ensemble methods build a conjunction of several
weak classi ers to learn a strong classi er that is more
successful than any individual classi er alone; ensembles have
been widely applied to various applications in the machine
learning literature [
        <xref ref-type="bibr" rid="ref20">20</xref>
        ]. It may be bene cial to build
ensemble models as news content and social context features each
have supplementary information that has the potential to
boost fake news detection performance. Finally, fake news
content or social context information may be noisy in the
raw feature space; projection methods refer to approaches
that lean projection functions to map between original
feature spaces (e.g., news content features and social context
features) and the latent feature spaces that may be more
useful for classi cation.
      </p>
      <p>Moreover, most existing approaches are supervised, which
requires a pre-annotated fake news ground truth dataset
to train a model. However, obtaining a reliable fake news
dataset is very time and labor intensive, as the process
often requires expert annotators to perform careful analysis of
claims and additional evidence, context, and reports from
authoritative sources. Thus, it is also important to
consider scenarios where limited or no labeled fake news pieces
are available in which semi-supervised or unsupervised
models can be applied. While the models created by
supervised classi cation methods may be more accurate given a
well-curated ground truth dataset for training, unsupervised
models can be more practical because unlabeled datasets are
easier to obtain.</p>
      <p>
        Application-oriented: Application-oriented fake news
research encompass research that goes into other areas beyond
fake news detection. We propose two major directions along
these lines: fake news di usion and fake news intervention.
Fake news di usion characterizes the di usion paths and
patterns of fake news on social media sites. Some early
research has shown that true information and misinformation
follow di erent patterns when propagating in online social
networks [18; 51]. Similarly, the di usion of fake news in
social media demonstrates its own characteristics that need
further investigation, such as social dimensions, life cycle,
spreader identi cation, etc. Social dimensions refer to the
heterogeneity and weak dependency of social connections
within di erent social communities. Users' perceptions of
fake news pieces are highly a ected by their like-minded
friends in social media (i.e., echo chambers), while the
degree di ers along di erent social dimensions. Thus, it is
worth exploring why and how di erent social dimensions
play a role in spreading fake news in terms of di erent
topics, such as political, education, sports, etc. The fake news
di usion process also has di erent stages in terms of
people's attentions and reactions as time goes by, resulting in
a unique life cycle. Research has shown that breaking news
and in-depth news demonstrate di erent life cycles in social
media [
        <xref ref-type="bibr" rid="ref10">10</xref>
        ]. Studying the life cycle of fake news will provide
deeper understanding of how particular stories \go viral"
from normal public discourse. Tracking the life cycle of fake
news on social media requires recording essential trajectories
of fake news di usion in general [71], as well as further
investigations of the process for speci c fake news pieces, such
as graph-based models and evolution-based models [
        <xref ref-type="bibr" rid="ref27">27</xref>
        ]. In
addition, identifying key spreaders of fake news is crucial to
mitigate the di usion scope in social media. Note that key
spreaders can be categorized in two ways, i.e., stance and
authenticity. Along the stance dimensions, spreaders can
either be (i) clari ers, who propose skeptical and opposing
viewpoints towards fake news and try to clarify them; or (ii)
persuaders, who spread fake news with supporting opinions
to persuade others to believe it. In this sense, it is
important to explore how to detect clari ers and persuaders and
better use them to control the dissemination of fake news.
From an authenticity perspective, spreaders could be either
human, bot, or cyborg. Social bots have been used to
intentionally spread fake news in social media, which motivates
further research to better characterize and detect malicious
accounts designed for propaganda.
      </p>
      <p>
        Finally, we also propose further research into fake news
intervention, which aims to reduce the e ects of fake news
by proactive intervention methods that minimize the spread
scope or reactive intervention methods after fake news goes
viral. Proactive fake news intervention methods try to (i)
remove malicious accounts that spread fake news or fake
news itself to isolate it from future consumers; (ii)
immunize users with true news to change the belief of users that
may already have been a ected by fake news. There is recent
research that attempts to use content-based immunization
and network-based immunization methods in
misinformation intervention [94; 97]. One approach uses a multivariate
Hawkes process to model both true news and fake news and
mitigate the spreading of fake news in real-time [
        <xref ref-type="bibr" rid="ref21">21</xref>
        ]. The
aforementioned spreader detection techniques can also be
applied to target certain users (e.g., persuaders) in social
media to stop spreading fake news, or other users (e.g.
clari ers) to maximize the spread of corresponding true news.
      </p>
    </sec>
    <sec id="sec-20">
      <title>CONCLUSION</title>
      <p>With the increasing popularity of social media, more and
more people consume news from social media instead of
traditional news media. However, social media has also been
used to spread fake news, which has strong negative impacts
on individual users and broader society. In this article, we
explored the fake news problem by reviewing existing
literature in two phases: characterization and detection. In
the characterization phase, we introduced the basic concepts
and principles of fake news in both traditional media and
social media. In the detection phase, we reviewed existing fake
news detection approaches from a data mining perspective,
including feature extraction and model construction. We
also further discussed the datasets, evaluation metrics, and
promising future directions in fake news detection research
and expand the eld to other applications.</p>
    </sec>
    <sec id="sec-21">
      <title>ACKNOWLEDGMENTS</title>
      <p>This material is based upon work supported by, or in part
by, the ONR grant N00014-16-1-2257.
Huan Liu. Leveraging the implicit structure within
social media for emergent rumor detection. In CIKM'15.
[71] Chengcheng Shao, Giovanni Luca Ciampaglia,
Alessandro Flammini, and Filippo Menczer. Hoaxy:
A platform for tracking online misinformation. In
WWW'16.
[72] Baoxu Shi and Tim Weninger. Fact checking in
heterogeneous information networks. In WWW'16.
[73] Kai Shu, Suhang Wang, Jiliang Tang, Reza Zafarani,
and Huan Liu. User identity linkage across online
social networks: A review. ACM SIGKDD Explorations
Newsletter, 18(2):5{17, 2017.
[74] Supasorn Suwajanakorn, Steven M Seitz, and Ira
Kemelmacher-Shlizerman. Synthesizing obama:
learning lip sync from audio. ACM Transactions on
Graphics (TOG), 36(4):95, 2017.
[75] Eugenio Tacchini, Gabriele Ballarin, Marco L
Della Vedova, Stefano Moret, and Luca de Alfaro.
Some like it hoax: Automated fake news detection
in social networks. arXiv preprint arXiv:1704.07506,
2017.
[76] Henri Tajfel and John C Turner. An integrative theory
of intergroup con ict. The social psychology of
intergroup relations, 33(47):74, 1979.
[77] Henri Tajfel and John C Turner. The social identity
theory of intergroup behavior. 2004.
[78] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang,
Jun Yan, and Qiaozhu Mei. Line: Large-scale
information network embedding. In WWW'15.
[79] Jiliang Tang, Yi Chang, and Huan Liu. Mining social
media with social theories: a survey. ACM SIGKDD
Explorations Newsletter, 15(2):20{29, 2014.
[80] Justus Thies, Michael Zollhofer, Marc Stamminger,
Christian Theobalt, and Matthias Nie ner. Face2face:
Real-time face capture and reenactment of rgb videos.</p>
      <p>In CVPR'16.
[81] Amos Tversky and Daniel Kahneman. Advances in
prospect theory: Cumulative representation of
uncertainty. Journal of Risk and uncertainty, 5(4):297{323,
1992.
[82] Udo Undeutsch. Beurteilung der glaubhaftigkeit von
aussagen. Handbuch der psychologie, 11:26{181, 1967.
[83] Andreas Vlachos and Sebastian Riedel. Fact checking:</p>
      <p>Task de nition and dataset construction. ACL'14.
[84] Aldert Vrij. Criteria-based content analysis: A
qualitative review of the rst 37 studies. Psychology, Public
Policy, and Law, 11(1):3, 2005.
[85] Suhang Wang, Charu Aggarwal, Jiliang Tang, and
Huan Liu. Attributed signed network embedding. In
CIKM'17.
[86] Suhang Wang, Jiliang Tang, Charu Aggarwal,
Yi Chang, and Huan Liu. Signed network embedding
in social media. In SDM'17.
[87] Suhang Wang, Jiliang Tang, Charu Aggarwal, and
Huan Liu. Linked document embedding for classi
cation. In CIKM'16.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          [1]
          <string-name>
            <given-names>Sadia</given-names>
            <surname>Afroz</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Michael</given-names>
            <surname>Brennan</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Rachel</given-names>
            <surname>Greenstadt</surname>
          </string-name>
          .
          <article-title>Detecting hoaxes, frauds, and deception in writing style online</article-title>
          .
          <source>In ISSP'12.</source>
        </mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation>
          [2]
          <string-name>
            <given-names>Hunt</given-names>
            <surname>Allcott</surname>
          </string-name>
          and
          <string-name>
            <given-names>Matthew</given-names>
            <surname>Gentzkow</surname>
          </string-name>
          .
          <article-title>Social media and fake news in the 2016 election</article-title>
          .
          <source>Technical report, National Bureau of Economic Research</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation>
          [3]
          <string-name>
            <surname>Solomon</surname>
            <given-names>E</given-names>
          </string-name>
          <string-name>
            <surname>Asch</surname>
            and
            <given-names>H</given-names>
          </string-name>
          <string-name>
            <surname>Guetzkow</surname>
          </string-name>
          .
          <article-title>E ects of group pressure upon the modi cation and distortion of judgments. Groups, leadership, and men</article-title>
          , pages
          <volume>222</volume>
          {
          <fpage>236</fpage>
          ,
          <year>1951</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation>
          [4]
          <string-name>
            <given-names>Meital</given-names>
            <surname>Balmas</surname>
          </string-name>
          .
          <article-title>When fake news becomes real: Combined exposure to multiple news sources and political attitudes of ine cacy, alienation, and cynicism</article-title>
          .
          <source>Communication Research</source>
          ,
          <volume>41</volume>
          (
          <issue>3</issue>
          ):
          <volume>430</volume>
          {
          <fpage>454</fpage>
          ,
          <year>2014</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation>
          [5]
          <string-name>
            <given-names>Michele</given-names>
            <surname>Banko</surname>
          </string-name>
          , Michael J Cafarella, Stephen Soderland, Matthew Broadhead, and
          <string-name>
            <given-names>Oren</given-names>
            <surname>Etzioni</surname>
          </string-name>
          .
          <article-title>Open information extraction from the web</article-title>
          .
          <source>In IJCAI'07.</source>
        </mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation>
          [6]
          <string-name>
            <given-names>Alessandro</given-names>
            <surname>Bessi</surname>
          </string-name>
          and
          <string-name>
            <given-names>Emilio</given-names>
            <surname>Ferrara</surname>
          </string-name>
          .
          <article-title>Social bots distort the 2016 us presidential election online discussion</article-title>
          .
          <source>First Monday</source>
          ,
          <volume>21</volume>
          (
          <issue>11</issue>
          ),
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation>
          [7]
          <string-name>
            <given-names>Prakhar</given-names>
            <surname>Biyani</surname>
          </string-name>
          , Kostas Tsioutsiouliklis,
          <string-name>
            <given-names>and John</given-names>
            <surname>Blackmer</surname>
          </string-name>
          .
          <article-title>" 8 amazing secrets for getting more clicks": Detecting clickbaits in news streams using article informality</article-title>
          .
          <source>In AAAI'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation>
          [8]
          <string-name>
            <given-names>Jonas</given-names>
            <surname>Nygaard</surname>
          </string-name>
          <article-title>Blom and Kenneth Reinecke Hansen</article-title>
          .
          <article-title>Click bait: Forward-reference as lure in online news headlines</article-title>
          .
          <source>Journal of Pragmatics</source>
          ,
          <volume>76</volume>
          :
          <fpage>87</fpage>
          {
          <fpage>100</fpage>
          ,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation>
          [9]
          <string-name>
            <surname>Paul</surname>
            <given-names>R Brewer</given-names>
          </string-name>
          , Dannagal Goldthwaite Young, and
          <string-name>
            <given-names>Michelle</given-names>
            <surname>Morreale</surname>
          </string-name>
          .
          <article-title>The impact of real news about fake news: Intertextual processes and political satire</article-title>
          .
          <source>International Journal of Public Opinion Research</source>
          ,
          <volume>25</volume>
          (
          <issue>3</issue>
          ):
          <volume>323</volume>
          {
          <fpage>343</fpage>
          ,
          <year>2013</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation>
          [10]
          <string-name>
            <surname>Carlos</surname>
            <given-names>Castillo</given-names>
          </string-name>
          , Mohammed El-Haddad,
          <article-title>Jurgen Pfeffer, and Matt Stempeck. Characterizing the life cycle of online news stories using social media reactions</article-title>
          .
          <source>In CSCW'14.</source>
        </mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation>
          [11]
          <string-name>
            <surname>Carlos</surname>
            <given-names>Castillo</given-names>
          </string-name>
          , Marcelo Mendoza, and
          <string-name>
            <given-names>Barbara</given-names>
            <surname>Poblete</surname>
          </string-name>
          .
          <article-title>Information credibility on twitter</article-title>
          .
          <source>In WWW'11.</source>
        </mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation>
          [12]
          <string-name>
            <surname>Abhijnan</surname>
            <given-names>Chakraborty</given-names>
          </string-name>
          , Bhargavi Paranjape, Sourya Kakarla, and
          <string-name>
            <given-names>Niloy</given-names>
            <surname>Ganguly</surname>
          </string-name>
          .
          <article-title>Stop clickbait: Detecting and preventing clickbaits in online news media</article-title>
          .
          <source>In ASONAM'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation>
          [13]
          <string-name>
            <surname>Yimin</surname>
            <given-names>Chen</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Niall J Conroy</surname>
          </string-name>
          , and Victoria L Rubin.
          <article-title>Misleading online content: Recognizing clickbait as false news</article-title>
          .
          <source>In Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection</source>
          , pages
          <volume>15</volume>
          {
          <fpage>19</fpage>
          . ACM,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation>
          [14]
          <string-name>
            <surname>Justin</surname>
            <given-names>Cheng</given-names>
          </string-name>
          , Michael Bernstein,
          <string-name>
            <surname>Cristian DanescuNiculescu-Mizil</surname>
            , and
            <given-names>Jure</given-names>
          </string-name>
          <string-name>
            <surname>Leskovec</surname>
          </string-name>
          .
          <article-title>Anyone can become a troll: Causes of trolling behavior in online discussions</article-title>
          .
          <source>In CSCW '17.</source>
        </mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation>
          [15]
          <string-name>
            <surname>Zi</surname>
            <given-names>Chu</given-names>
          </string-name>
          , Steven Gianvecchio,
          <string-name>
            <given-names>Haining</given-names>
            <surname>Wang</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Sushil</given-names>
            <surname>Jajodia</surname>
          </string-name>
          .
          <article-title>Detecting automation of twitter accounts: Are you a human, bot, or cyborg</article-title>
          ?
          <source>IEEE Transactions on Dependable and Secure Computing</source>
          ,
          <volume>9</volume>
          (
          <issue>6</issue>
          ):
          <volume>811</volume>
          {
          <fpage>824</fpage>
          ,
          <year>2012</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation>
          [16]
          <string-name>
            <given-names>Giovanni</given-names>
            <surname>Luca</surname>
          </string-name>
          <string-name>
            <surname>Ciampaglia</surname>
          </string-name>
          , Prashant Shiralkar, Luis M Rocha,
          <string-name>
            <given-names>Johan</given-names>
            <surname>Bollen</surname>
          </string-name>
          , Filippo Menczer, and
          <string-name>
            <given-names>Alessandro</given-names>
            <surname>Flammini</surname>
          </string-name>
          .
          <article-title>Computational fact checking from knowledge networks</article-title>
          .
          <source>PloS one</source>
          ,
          <volume>10</volume>
          (
          <issue>6</issue>
          ):e0128193,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation>
          [17]
          <string-name>
            <surname>Niall J Conroy</surname>
            , Victoria L Rubin, and
            <given-names>Yimin</given-names>
          </string-name>
          <string-name>
            <surname>Chen</surname>
          </string-name>
          .
          <article-title>Automatic deception detection: Methods for nding fake news</article-title>
          .
          <source>Proceedings of the Association for Information Science and Technology</source>
          ,
          <volume>52</volume>
          (
          <issue>1</issue>
          ):1{
          <issue>4</issue>
          ,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref18">
        <mixed-citation>
          [18]
          <string-name>
            <given-names>Michela</given-names>
            <surname>Del Vicario</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Alessandro</given-names>
            <surname>Bessi</surname>
          </string-name>
          , Fabiana Zollo, Fabio Petroni, Antonio Scala, Guido Caldarelli,
          <string-name>
            <given-names>H Eugene</given-names>
            <surname>Stanley</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Walter</given-names>
            <surname>Quattrociocchi</surname>
          </string-name>
          .
          <article-title>The spreading of misinformation online</article-title>
          .
          <source>Proceedings of the National Academy of Sciences</source>
          ,
          <volume>113</volume>
          (
          <issue>3</issue>
          ):
          <volume>554</volume>
          {
          <fpage>559</fpage>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref19">
        <mixed-citation>
          [19]
          <string-name>
            <given-names>Michela</given-names>
            <surname>Del Vicario</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Gianna</given-names>
            <surname>Vivaldo</surname>
          </string-name>
          , Alessandro Bessi, Fabiana Zollo, Antonio Scala, Guido Caldarelli, and
          <string-name>
            <given-names>Walter</given-names>
            <surname>Quattrociocchi</surname>
          </string-name>
          .
          <article-title>Echo chambers: Emotional contagion and group polarization on facebook</article-title>
          .
          <source>Scienti c Reports</source>
          ,
          <volume>6</volume>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref20">
        <mixed-citation>
          [20]
          <string-name>
            <surname>Thomas</surname>
            <given-names>G Dietterich</given-names>
          </string-name>
          et al.
          <article-title>Ensemble methods in machine learning</article-title>
          .
          <source>Multiple classi er systems</source>
          ,
          <year>1857</year>
          :
          <volume>1</volume>
          {
          <fpage>15</fpage>
          ,
          <year>2000</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref21">
        <mixed-citation>
          [21]
          <string-name>
            <surname>Mehrdad</surname>
            <given-names>Farajtabar</given-names>
          </string-name>
          , Jiachen Yang, Xiaojing Ye, Huan Xu, Rakshit Trivedi, Elias Khalil,
          <string-name>
            <given-names>Shuang</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Le</given-names>
            <surname>Song</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Hongyuan</given-names>
            <surname>Zha</surname>
          </string-name>
          .
          <article-title>Fake news mitigation via point process based intervention</article-title>
          .
          <source>arXiv preprint arXiv:1703.07823</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref22">
        <mixed-citation>
          [22]
          <string-name>
            <surname>Song</surname>
            <given-names>Feng</given-names>
          </string-name>
          , Ritwik Banerjee, and
          <string-name>
            <given-names>Yejin</given-names>
            <surname>Choi</surname>
          </string-name>
          .
          <article-title>Syntactic stylometry for deception detection</article-title>
          .
          <source>In ACL'12.</source>
        </mixed-citation>
      </ref>
      <ref id="ref23">
        <mixed-citation>
          [23]
          <string-name>
            <surname>Emilio</surname>
            <given-names>Ferrara</given-names>
          </string-name>
          , Onur Varol, Clayton Davis,
          <string-name>
            <given-names>Filippo</given-names>
            <surname>Menczer</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Alessandro</given-names>
            <surname>Flammini</surname>
          </string-name>
          .
          <article-title>The rise of social bots</article-title>
          .
          <source>Communications of the ACM</source>
          ,
          <volume>59</volume>
          (
          <issue>7</issue>
          ):
          <volume>96</volume>
          {
          <fpage>104</fpage>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref24">
        <mixed-citation>
          [24]
          <string-name>
            <given-names>Johannes</given-names>
            <surname>Fu</surname>
          </string-name>
          <article-title>rnkranz. A study using n-gram features for text categorization</article-title>
          .
          <source>Austrian Research Institute for Arti cal Intelligence</source>
          ,
          <volume>3</volume>
          (
          <year>1998</year>
          ):
          <volume>1</volume>
          {
          <fpage>10</fpage>
          ,
          <year>1998</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref25">
        <mixed-citation>
          [25]
          <string-name>
            <given-names>Ashutosh</given-names>
            <surname>Garg</surname>
          </string-name>
          and
          <string-name>
            <given-names>Dan</given-names>
            <surname>Roth</surname>
          </string-name>
          .
          <article-title>Understanding probabilistic classi ers</article-title>
          .
          <source>ECML'01.</source>
        </mixed-citation>
      </ref>
      <ref id="ref26">
        <mixed-citation>
          [26]
          <string-name>
            <surname>Matthew</surname>
            <given-names>Gentzkow</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Jesse M Shapiro</surname>
          </string-name>
          , and Daniel F Stone.
          <article-title>Media bias in the marketplace:</article-title>
          <source>Theory. Technical report, National Bureau of Economic Research</source>
          ,
          <year>2014</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref27">
        <mixed-citation>
          [27]
          <string-name>
            <surname>Adrien</surname>
            <given-names>Guille</given-names>
          </string-name>
          , Hakim Hacid, Cecile Favre, and
          <article-title>Djamel A Zighed. Information di usion in online social networks: A survey</article-title>
          .
          <source>ACM Sigmod Record</source>
          ,
          <volume>42</volume>
          (
          <issue>2</issue>
          ):
          <volume>17</volume>
          {
          <fpage>28</fpage>
          ,
          <year>2013</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref28">
        <mixed-citation>
          [28]
          <string-name>
            <surname>Aditi</surname>
            <given-names>Gupta</given-names>
          </string-name>
          , Hemank Lamba, Ponnurangam Kumaraguru, and
          <string-name>
            <given-names>Anupam</given-names>
            <surname>Joshi</surname>
          </string-name>
          .
          <article-title>Faking sandy: characterizing and identifying fake images on twitter during hurricane sandy</article-title>
          .
          <source>In WWW'13.</source>
        </mixed-citation>
      </ref>
      <ref id="ref29">
        <mixed-citation>
          [29]
          <string-name>
            <surname>Manish</surname>
            <given-names>Gupta</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Peixiang</given-names>
            <surname>Zhao</surname>
          </string-name>
          , and Jiawei Han.
          <article-title>Evaluating event credibility on twitter</article-title>
          .
          <source>In PSDM'12.</source>
        </mixed-citation>
      </ref>
      <ref id="ref30">
        <mixed-citation>
          [30]
          <string-name>
            <surname>David J Hand and Robert J Till</surname>
          </string-name>
          .
          <article-title>A simple generalisation of the area under the roc curve for multiple class classi cation problems</article-title>
          .
          <source>Machine learning</source>
          ,
          <year>2001</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref31">
        <mixed-citation>
          [31]
          <string-name>
            <surname>Naeemul</surname>
            <given-names>Hassan</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Chengkai</given-names>
            <surname>Li</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Mark</given-names>
            <surname>Tremayne</surname>
          </string-name>
          .
          <article-title>Detecting check-worthy factual claims in presidential debates</article-title>
          .
          <source>In CIKM'15.</source>
        </mixed-citation>
      </ref>
      <ref id="ref32">
        <mixed-citation>
          [32]
          <string-name>
            <given-names>John</given-names>
            <surname>Houvardas</surname>
          </string-name>
          and
          <string-name>
            <given-names>Efstathios</given-names>
            <surname>Stamatatos</surname>
          </string-name>
          .
          <article-title>N-gram feature selection for authorship identi cation</article-title>
          .
          <source>Arti - cial Intelligence: Methodology, Systems, and Applications</source>
          , pages
          <volume>77</volume>
          {
          <fpage>86</fpage>
          ,
          <year>2006</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref33">
        <mixed-citation>
          [33]
          <string-name>
            <surname>Xia</surname>
            <given-names>Hu</given-names>
          </string-name>
          , Jiliang Tang,
          <string-name>
            <given-names>Huiji</given-names>
            <surname>Gao</surname>
          </string-name>
          , and Huan Liu.
          <article-title>Social spammer detection with sentiment information</article-title>
          .
          <source>In ICDM'14.</source>
        </mixed-citation>
      </ref>
      <ref id="ref34">
        <mixed-citation>
          [34]
          <string-name>
            <surname>Xia</surname>
            <given-names>Hu</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jiliang</given-names>
            <surname>Tang</surname>
          </string-name>
          , and Huan Liu.
          <article-title>Online social spammer detection</article-title>
          .
          <source>In AAAI'14</source>
          , pages
          <fpage>59</fpage>
          {
          <fpage>65</fpage>
          ,
          <year>2014</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref35">
        <mixed-citation>
          [35]
          <string-name>
            <surname>Xia</surname>
            <given-names>Hu</given-names>
          </string-name>
          , Jiliang Tang, Yanchao Zhang, and Huan Liu.
          <article-title>Social spammer detection in microblogging</article-title>
          .
          <source>In IJCAI'13.</source>
        </mixed-citation>
      </ref>
      <ref id="ref36">
        <mixed-citation>
          [36]
          <string-name>
            <surname>Zhiwei</surname>
            <given-names>Jin</given-names>
          </string-name>
          , Juan Cao,
          <string-name>
            <surname>Yu-Gang Jiang</surname>
          </string-name>
          , and Yongdong Zhang.
          <article-title>News credibility evaluation on microblog with a hierarchical propagation model</article-title>
          .
          <source>In ICDM'14.</source>
        </mixed-citation>
      </ref>
      <ref id="ref37">
        <mixed-citation>
          [37]
          <string-name>
            <surname>Zhiwei</surname>
            <given-names>Jin</given-names>
          </string-name>
          , Juan Cao, Yongdong Zhang, and
          <string-name>
            <given-names>Jiebo</given-names>
            <surname>Luo</surname>
          </string-name>
          .
          <article-title>News veri cation by exploiting con icting social viewpoints in microblogs</article-title>
          .
          <source>In AAAI'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref38">
        <mixed-citation>
          [38]
          <string-name>
            <surname>Zhiwei</surname>
            <given-names>Jin</given-names>
          </string-name>
          , Juan Cao, Yongdong Zhang, Jianshe Zhou, and
          <string-name>
            <given-names>Qi</given-names>
            <surname>Tian</surname>
          </string-name>
          .
          <article-title>Novel visual and statistical image features for microblogs news veri cation</article-title>
          .
          <source>IEEE Transactions on Multimedia</source>
          ,
          <volume>19</volume>
          (
          <issue>3</issue>
          ):
          <volume>598</volume>
          {
          <fpage>608</fpage>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref39">
        <mixed-citation>
          [39]
          <string-name>
            <given-names>Daniel</given-names>
            <surname>Kahneman</surname>
          </string-name>
          and
          <string-name>
            <given-names>Amos</given-names>
            <surname>Tversky</surname>
          </string-name>
          .
          <article-title>Prospect theory: An analysis of decision under risk</article-title>
          .
          <source>Econometrica: Journal of the econometric society</source>
          , pages
          <volume>263</volume>
          {
          <fpage>291</fpage>
          ,
          <year>1979</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref40">
        <mixed-citation>
          [40]
          <string-name>
            <surname>Jean-Noel Kapferer</surname>
          </string-name>
          .
          <source>Rumors: Uses, Interpretation and Necessity. Routledge</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref41">
        <mixed-citation>
          [41]
          <string-name>
            <surname>David</surname>
            <given-names>O</given-names>
          </string-name>
          <string-name>
            <surname>Klein and Joshua R Wueller.</surname>
          </string-name>
          <article-title>Fake news: A legal perspective</article-title>
          .
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref42">
        <mixed-citation>
          [42]
          <string-name>
            <surname>Sejeong</surname>
            <given-names>Kwon</given-names>
          </string-name>
          , Meeyoung Cha, Kyomin Jung, Wei Chen, and
          <string-name>
            <given-names>Yajun</given-names>
            <surname>Wang</surname>
          </string-name>
          .
          <article-title>Prominent features of rumor propagation in online social media</article-title>
          .
          <source>In ICDM'13</source>
          , pages
          <fpage>1103</fpage>
          {
          <fpage>1108</fpage>
          . IEEE,
          <year>2013</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref43">
        <mixed-citation>
          [43]
          <string-name>
            <surname>Yann</surname>
            <given-names>LeCun</given-names>
          </string-name>
          , Yoshua Bengio, and Geo rey Hinton.
          <article-title>Deep learning</article-title>
          .
          <source>Nature</source>
          ,
          <volume>521</volume>
          (
          <issue>7553</issue>
          ):
          <volume>436</volume>
          {
          <fpage>444</fpage>
          ,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref44">
        <mixed-citation>
          [44]
          <string-name>
            <given-names>Kyumin</given-names>
            <surname>Lee</surname>
          </string-name>
          ,
          <string-name>
            <given-names>James</given-names>
            <surname>Caverlee</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Steve</given-names>
            <surname>Webb</surname>
          </string-name>
          .
          <article-title>Uncovering social spammers: social honeypots+ machine learning</article-title>
          .
          <source>In SIGIR'10.</source>
        </mixed-citation>
      </ref>
      <ref id="ref45">
        <mixed-citation>
          [45]
          <string-name>
            <given-names>Tony</given-names>
            <surname>Lesce</surname>
          </string-name>
          . Scan:
          <article-title>Deception detection by scienti c content analysis</article-title>
          .
          <source>Law and Order</source>
          ,
          <volume>38</volume>
          (
          <issue>8</issue>
          ):3{
          <issue>6</issue>
          ,
          <year>1990</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref46">
        <mixed-citation>
          [46]
          <string-name>
            <given-names>Yaliang</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Jing</given-names>
            <surname>Gao</surname>
          </string-name>
          , Chuishi Meng,
          <string-name>
            <given-names>Qi</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Lu</given-names>
            <surname>Su</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Bo</given-names>
            <surname>Zhao</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Wei</given-names>
            <surname>Fan</surname>
          </string-name>
          , and Jiawei Han.
          <article-title>A survey on truth discovery</article-title>
          .
          <source>ACM Sigkdd Explorations Newsletter</source>
          ,
          <volume>17</volume>
          (
          <issue>2</issue>
          ):1{
          <fpage>16</fpage>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref47">
        <mixed-citation>
          [47]
          <string-name>
            <surname>Charles</surname>
            <given-names>X Ling</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jin</given-names>
            <surname>Huang</surname>
          </string-name>
          ,
          <string-name>
            <given-names>and Harry</given-names>
            <surname>Zhang</surname>
          </string-name>
          .
          <article-title>Auc: a statistically consistent and more discriminating measure than accuracy</article-title>
          .
        </mixed-citation>
      </ref>
      <ref id="ref48">
        <mixed-citation>
          [48]
          <string-name>
            <surname>Jing</surname>
            <given-names>Ma</given-names>
          </string-name>
          , Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J Jansen,
          <string-name>
            <surname>Kam-Fai Wong</surname>
            , and
            <given-names>Meeyoung</given-names>
          </string-name>
          <string-name>
            <surname>Cha</surname>
          </string-name>
          .
          <article-title>Detecting rumors from microblogs with recurrent neural networks</article-title>
          .
        </mixed-citation>
      </ref>
      <ref id="ref49">
        <mixed-citation>
          [49]
          <string-name>
            <surname>Jing</surname>
            <given-names>Ma</given-names>
          </string-name>
          , Wei Gao, Zhongyu Wei, Yueming Lu, and
          <string-name>
            <surname>Kam-Fai Wong</surname>
          </string-name>
          .
          <article-title>Detect rumors using time series of social context information on microblogging websites</article-title>
          .
          <source>In CIKM'15.</source>
        </mixed-citation>
      </ref>
      <ref id="ref50">
        <mixed-citation>
          [50]
          <string-name>
            <given-names>Amr</given-names>
            <surname>Magdy</surname>
          </string-name>
          and
          <string-name>
            <given-names>Nayer</given-names>
            <surname>Wanas</surname>
          </string-name>
          .
          <article-title>Web-based statistical fact checking of textual documents</article-title>
          .
          <source>In Proceedings of the 2nd international workshop on Search and mining user-generated contents</source>
          , pages
          <volume>103</volume>
          {
          <fpage>110</fpage>
          . ACM,
          <year>2010</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref51">
        <mixed-citation>
          [51]
          <string-name>
            <given-names>Filippo</given-names>
            <surname>Menczer</surname>
          </string-name>
          .
          <article-title>The spread of misinformation in social media</article-title>
          .
          <source>In WWW'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref52">
        <mixed-citation>
          [52]
          <string-name>
            <given-names>Tanushree</given-names>
            <surname>Mitra</surname>
          </string-name>
          and
          <string-name>
            <given-names>Eric</given-names>
            <surname>Gilbert</surname>
          </string-name>
          .
          <article-title>Credbank: A largescale social media corpus with associated credibility annotations</article-title>
          .
          <source>In ICWSM'15.</source>
        </mixed-citation>
      </ref>
      <ref id="ref53">
        <mixed-citation>
          [53]
          <string-name>
            <surname>Saif</surname>
            <given-names>M Mohammad</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Parinaz</given-names>
            <surname>Sobhani</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Svetlana</given-names>
            <surname>Kiritchenko</surname>
          </string-name>
          .
          <article-title>Stance and sentiment in tweets.</article-title>
        </mixed-citation>
      </ref>
      <ref id="ref54">
        <mixed-citation>
          <source>ACM Transactions on Internet Technology (TOIT)</source>
          ,
          <volume>17</volume>
          (
          <issue>3</issue>
          ):
          <fpage>26</fpage>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref55">
        <mixed-citation>
          [54]
          <string-name>
            <surname>Fred</surname>
            <given-names>Morstatter</given-names>
          </string-name>
          , Harsh Dani, Justin Sampson, and Huan Liu.
          <article-title>Can one tamper with the sample api?: Toward neutralizing bias from spam and bot content</article-title>
          .
          <source>In WWW'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref56">
        <mixed-citation>
          [55]
          <string-name>
            <surname>Fred</surname>
            <given-names>Morstatter</given-names>
          </string-name>
          , Liang Wu,
          <string-name>
            <surname>Tahora H Nazer</surname>
          </string-name>
          ,
          <article-title>Kathleen M Carley,</article-title>
          and
          <string-name>
            <given-names>Huan</given-names>
            <surname>Liu</surname>
          </string-name>
          .
          <article-title>A new approach to bot detection: Striking the balance between precision and recall</article-title>
          .
          <source>In ASONAM'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref57">
        <mixed-citation>
          [56]
          <string-name>
            <given-names>Subhabrata</given-names>
            <surname>Mukherjee</surname>
          </string-name>
          and
          <string-name>
            <given-names>Gerhard</given-names>
            <surname>Weikum</surname>
          </string-name>
          .
          <article-title>Leveraging joint interactions for credibility analysis in news communities</article-title>
          .
          <source>In CIKM'15.</source>
        </mixed-citation>
      </ref>
      <ref id="ref58">
        <mixed-citation>
          [57]
          <string-name>
            <given-names>Eni</given-names>
            <surname>Mustafaraj</surname>
          </string-name>
          and
          <article-title>Panagiotis Takis Metaxas. The fake news spreading plague: Was it preventable</article-title>
          ?
          <source>arXiv preprint arXiv:1703.06988</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref59">
        <mixed-citation>
          [58]
          <string-name>
            <surname>Raymond</surname>
            <given-names>S Nickerson.</given-names>
          </string-name>
          <article-title>Con rmation bias: A ubiquitous phenomenon in many guises</article-title>
          .
          <source>Review of general psychology</source>
          ,
          <volume>2</volume>
          (
          <issue>2</issue>
          ):
          <fpage>175</fpage>
          ,
          <year>1998</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref60">
        <mixed-citation>
          [59]
          <string-name>
            <given-names>Brendan</given-names>
            <surname>Nyhan</surname>
          </string-name>
          and
          <article-title>Jason Rei er</article-title>
          .
          <article-title>When corrections fail: The persistence of political misperceptions</article-title>
          .
          <source>Political Behavior</source>
          ,
          <volume>32</volume>
          (
          <issue>2</issue>
          ):
          <volume>303</volume>
          {
          <fpage>330</fpage>
          ,
          <year>2010</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref61">
        <mixed-citation>
          [60]
          <string-name>
            <given-names>Christopher</given-names>
            <surname>Paul</surname>
          </string-name>
          and
          <string-name>
            <given-names>Miriam</given-names>
            <surname>Matthews</surname>
          </string-name>
          .
          <article-title>The russian rehose of falsehood propaganda model</article-title>
          .
        </mixed-citation>
      </ref>
      <ref id="ref62">
        <mixed-citation>
          [61]
          <string-name>
            <surname>Dong ping Tian</surname>
          </string-name>
          et al.
          <article-title>A review on image feature extraction and representation techniques</article-title>
          .
          <source>International Journal of Multimedia and Ubiquitous Engineering</source>
          ,
          <volume>8</volume>
          (
          <issue>4</issue>
          ):
          <volume>385</volume>
          {
          <fpage>396</fpage>
          ,
          <year>2013</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref63">
        <mixed-citation>
          [62]
          <string-name>
            <surname>Martin</surname>
            <given-names>Potthast</given-names>
          </string-name>
          , Johannes Kiesel, Kevin Reinartz, Janek Bevendor , and
          <string-name>
            <given-names>Benno</given-names>
            <surname>Stein</surname>
          </string-name>
          .
          <article-title>A stylometric inquiry into hyperpartisan and fake news</article-title>
          .
          <source>arXiv preprint arXiv:1702.05638</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref64">
        <mixed-citation>
          [63]
          <string-name>
            <surname>Martin</surname>
            <given-names>Potthast</given-names>
          </string-name>
          , Sebastian Kopsel, Benno Stein, and
          <string-name>
            <given-names>Matthias</given-names>
            <surname>Hagen</surname>
          </string-name>
          .
          <article-title>Clickbait detection</article-title>
          .
          <source>In European Conference on Information Retrieval</source>
          , pages
          <volume>810</volume>
          {
          <fpage>817</fpage>
          . Springer,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref65">
        <mixed-citation>
          [64]
          <string-name>
            <surname>Vahed</surname>
            <given-names>Qazvinian</given-names>
          </string-name>
          , Emily Rosengren,
          <string-name>
            <surname>Dragomir R Radev</surname>
            , and
            <given-names>Qiaozhu</given-names>
          </string-name>
          <string-name>
            <surname>Mei</surname>
          </string-name>
          .
          <article-title>Rumor has it: Identifying misinformation in microblogs</article-title>
          .
          <source>In EMNLP'11.</source>
        </mixed-citation>
      </ref>
      <ref id="ref66">
        <mixed-citation>
          [65]
          <string-name>
            <surname>Walter</surname>
            <given-names>Quattrociocchi</given-names>
          </string-name>
          , Antonio Scala, and Cass R Sunstein.
          <source>Echo chambers on facebook</source>
          .
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref67">
        <mixed-citation>
          [66]
          <string-name>
            <surname>Victoria</surname>
            <given-names>L Rubin</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Yimin Chen</surname>
          </string-name>
          , and
          <string-name>
            <surname>Niall</surname>
          </string-name>
          J Conroy.
          <article-title>Deception detection for news: three types of fakes</article-title>
          .
          <source>Proceedings of the Association for Information Science and Technology</source>
          ,
          <volume>52</volume>
          (
          <issue>1</issue>
          ):1{
          <issue>4</issue>
          ,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref68">
        <mixed-citation>
          [67]
          <string-name>
            <surname>Victoria</surname>
            <given-names>L Rubin</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Niall J Conroy</surname>
            , Yimin Chen, and
            <given-names>Sarah</given-names>
          </string-name>
          <string-name>
            <surname>Cornwell</surname>
          </string-name>
          .
          <article-title>Fake news or truth? using satirical cues to detect potentially misleading news</article-title>
          .
          <source>In Proceedings of NAACL-HLT</source>
          , pages
          <volume>7</volume>
          {
          <fpage>17</fpage>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref69">
        <mixed-citation>
          [68]
          <string-name>
            <surname>Victoria</surname>
            <given-names>L Rubin</given-names>
          </string-name>
          and
          <string-name>
            <given-names>Tatiana</given-names>
            <surname>Lukoianova</surname>
          </string-name>
          .
          <article-title>Truth and deception at the rhetorical structure level</article-title>
          .
          <source>Journal of the Association for Information Science and Technology</source>
          ,
          <volume>66</volume>
          (
          <issue>5</issue>
          ):
          <volume>905</volume>
          {
          <fpage>917</fpage>
          ,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref70">
        <mixed-citation>
          [69]
          <string-name>
            <surname>Natali</surname>
            <given-names>Ruchansky</given-names>
          </string-name>
          , Sungyong Seo, and Yan Liu.
          <article-title>Csi: A hybrid deep model for fake news</article-title>
          .
          <source>arXiv preprint arXiv:1703.06959</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref71">
        <mixed-citation>
          [70]
          <string-name>
            <surname>Justin</surname>
            <given-names>Sampson</given-names>
          </string-name>
          , Fred Morstatter,
          <string-name>
            <surname>Liang Wu</surname>
          </string-name>
          , and
        </mixed-citation>
      </ref>
      <ref id="ref72">
        <mixed-citation>
          [88]
          <string-name>
            <surname>Suhang</surname>
            <given-names>Wang</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jiliang</given-names>
            <surname>Tang</surname>
          </string-name>
          , Fred Morstatter, and Huan Liu.
          <article-title>Paired restricted boltzmann machine for linked data</article-title>
          .
          <source>In CIKM'16.</source>
        </mixed-citation>
      </ref>
      <ref id="ref73">
        <mixed-citation>
          [89]
          <string-name>
            <surname>Suhang</surname>
            <given-names>Wang</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Yilin</surname>
            <given-names>Wang</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jiliang</given-names>
            <surname>Tang</surname>
          </string-name>
          , Kai Shu, Suhas Ranganath, and Huan Liu.
          <article-title>What your images reveal: Exploiting visual contents for point-of-interest recommendation</article-title>
          .
          <source>In WWW'17.</source>
        </mixed-citation>
      </ref>
      <ref id="ref74">
        <mixed-citation>
          [90]
          <string-name>
            <given-names>William</given-names>
            <surname>Yang Wang</surname>
          </string-name>
          .
          <article-title>" liar, liar pants on re": A new benchmark dataset for fake news detection</article-title>
          .
          <source>arXiv preprint arXiv:1705.00648</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref75">
        <mixed-citation>
          [91]
          <string-name>
            <surname>Yilin</surname>
            <given-names>Wang</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Suhang</surname>
            <given-names>Wang</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jiliang</given-names>
            <surname>Tang</surname>
          </string-name>
          , Huan Liu, and
          <string-name>
            <given-names>Baoxin</given-names>
            <surname>Li</surname>
          </string-name>
          .
          <article-title>Unsupervised sentiment analysis for social media images</article-title>
          .
          <source>In IJCAI</source>
          , pages
          <volume>2378</volume>
          {
          <fpage>2379</fpage>
          ,
          <year>2015</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref76">
        <mixed-citation>
          [92]
          <string-name>
            <given-names>Andrew</given-names>
            <surname>Ward</surname>
          </string-name>
          ,
          <string-name>
            <given-names>L</given-names>
            <surname>Ross</surname>
          </string-name>
          ,
          <string-name>
            <given-names>E</given-names>
            <surname>Reed</surname>
          </string-name>
          ,
          <string-name>
            <given-names>E</given-names>
            <surname>Turiel</surname>
          </string-name>
          , and
          <string-name>
            <given-names>T</given-names>
            <surname>Brown</surname>
          </string-name>
          .
          <article-title>Naive realism in everyday life: Implications for social con ict and misunderstanding</article-title>
          .
          <source>Values and knowledge</source>
          , pages
          <volume>103</volume>
          {
          <fpage>135</fpage>
          ,
          <year>1997</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref77">
        <mixed-citation>
          [93]
          <string-name>
            <given-names>Gerhard</given-names>
            <surname>Weikum</surname>
          </string-name>
          .
          <article-title>What computers should know, shouldn't know, and shouldn't believe</article-title>
          .
          <source>In WWW'17.</source>
        </mixed-citation>
      </ref>
      <ref id="ref78">
        <mixed-citation>
          [94]
          <string-name>
            <given-names>L</given-names>
            <surname>Wu</surname>
          </string-name>
          ,
          <string-name>
            <given-names>F</given-names>
            <surname>Morstatter</surname>
          </string-name>
          ,
          <string-name>
            <given-names>X</given-names>
            <surname>Hu</surname>
          </string-name>
          , and
          <string-name>
            <given-names>H</given-names>
            <surname>Liu</surname>
          </string-name>
          .
          <article-title>Chapter 5: Mining misinformation in social media</article-title>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref79">
        <mixed-citation>
          [95]
          <string-name>
            <surname>Liang</surname>
            <given-names>Wu</given-names>
          </string-name>
          , Xia Hu, Fred Morstatter, and Huan Liu.
          <article-title>Adaptive spammer detection with sparse group modeling</article-title>
          .
          <source>In ICWSM'17.</source>
        </mixed-citation>
      </ref>
      <ref id="ref80">
        <mixed-citation>
          [96]
          <string-name>
            <surname>Liang</surname>
            <given-names>Wu</given-names>
          </string-name>
          ,
          <string-name>
            <given-names>Jundong</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Xia</given-names>
            <surname>Hu</surname>
          </string-name>
          , and Huan Liu.
          <article-title>Gleaning wisdom from the past: Early detection of emerging rumors in social media</article-title>
          .
          <source>In SDM'17.</source>
        </mixed-citation>
      </ref>
      <ref id="ref81">
        <mixed-citation>
          [97]
          <string-name>
            <surname>Liang</surname>
            <given-names>Wu</given-names>
          </string-name>
          , Fred Morstatter, Xia Hu, and Huan Liu.
          <article-title>Mining misinformation in social media</article-title>
          .
          <source>Big Data in Complex and Social Networks</source>
          , pages
          <volume>123</volume>
          {
          <fpage>152</fpage>
          ,
          <year>2016</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref82">
        <mixed-citation>
          [98]
          <string-name>
            <surname>You</surname>
            <given-names>Wu</given-names>
          </string-name>
          , Pankaj K Agarwal,
          <string-name>
            <given-names>Chengkai</given-names>
            <surname>Li</surname>
          </string-name>
          ,
          <string-name>
            <given-names>Jun</given-names>
            <surname>Yang</surname>
          </string-name>
          , and
          <string-name>
            <given-names>Cong</given-names>
            <surname>Yu</surname>
          </string-name>
          .
          <article-title>Toward computational fact-checking</article-title>
          .
          <source>Proceedings of the VLDB Endowment</source>
          ,
          <volume>7</volume>
          (
          <issue>7</issue>
          ):
          <volume>589</volume>
          {
          <fpage>600</fpage>
          ,
          <year>2014</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref83">
        <mixed-citation>
          [99]
          <string-name>
            <surname>Fan</surname>
            <given-names>Yang</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Yang</surname>
            <given-names>Liu</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Xiaohui Yu</surname>
            , and
            <given-names>Min</given-names>
          </string-name>
          <string-name>
            <surname>Yang</surname>
          </string-name>
          .
          <article-title>Automatic detection of rumor on sina weibo</article-title>
          .
          <source>In Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics, page 13. ACM</source>
          ,
          <year>2012</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref84">
        <mixed-citation>
          [100]
          <string-name>
            <surname>Robert</surname>
            <given-names>B</given-names>
          </string-name>
          <string-name>
            <surname>Zajonc</surname>
          </string-name>
          .
          <article-title>Attitudinal e ects of mere exposure</article-title>
          .
          <source>Journal of personality and social psychology</source>
          ,
          <volume>9</volume>
          (
          <issue>2p2</issue>
          ):
          <fpage>1</fpage>
          ,
          <year>1968</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref85">
        <mixed-citation>
          [101]
          <string-name>
            <surname>Robert</surname>
            <given-names>B</given-names>
          </string-name>
          <string-name>
            <surname>Zajonc</surname>
          </string-name>
          .
          <article-title>Mere exposure: A gateway to the subliminal</article-title>
          .
          <source>Current directions in psychological science</source>
          ,
          <volume>10</volume>
          (
          <issue>6</issue>
          ):
          <volume>224</volume>
          {
          <fpage>228</fpage>
          ,
          <year>2001</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref86">
        <mixed-citation>
          [102]
          <string-name>
            <surname>Arkaitz</surname>
            <given-names>Zubiaga</given-names>
          </string-name>
          , Ahmet Aker, Kalina Bontcheva, Maria Liakata, and
          <string-name>
            <given-names>Rob</given-names>
            <surname>Procter</surname>
          </string-name>
          .
          <article-title>Detection and resolution of rumours in social media: A survey</article-title>
          .
          <source>arXiv preprint arXiv:1704.00656</source>
          ,
          <year>2017</year>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>

