{
    "article": {
        "@xmlns:xlink": "http://www.w3.org/1999/xlink",
        "front": {
            "journal-meta": {
                "journal-title-group": {
                    "journal-title": "Procedia Computer Science"
                }
            },
            "article-meta": {
                "title-group": {
                    "article-title": "Sarcasm classification: A novel approach by using Content Based Sarcasm classification: A novel approach by using Content Based Sarcasm classification: A novel approach by using Content Based Feature Selection Method Feature Selection Method Feature Selection Method"
                },
                "contrib-group": {
                    "contrib": [
                        {
                            "@contrib-type": "author",
                            "string-name": "H M Keerthi Kumar",
                            "xref": [
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff0",
                                    "#text": "0"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff1",
                                    "#text": "1"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff2",
                                    "#text": "2"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff3",
                                    "#text": "3"
                                }
                            ]
                        },
                        {
                            "@contrib-type": "author",
                            "string-name": "B S Harish",
                            "email": "bsharish@sjce.ac.in",
                            "xref": [
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff0",
                                    "#text": "0"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff1",
                                    "#text": "1"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff2",
                                    "#text": "2"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff3",
                                    "#text": "3"
                                }
                            ]
                        },
                        {
                            "@contrib-type": "author",
                            "string-name": "H M Keerthi Kumar",
                            "xref": [
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff0",
                                    "#text": "0"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff1",
                                    "#text": "1"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff2",
                                    "#text": "2"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff3",
                                    "#text": "3"
                                }
                            ]
                        },
                        {
                            "@contrib-type": "author",
                            "string-name": "B S Harish a",
                            "xref": [
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff0",
                                    "#text": "0"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff1",
                                    "#text": "1"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff2",
                                    "#text": "2"
                                },
                                {
                                    "@ref-type": "aff",
                                    "@rid": "aff3",
                                    "#text": "3"
                                }
                            ]
                        }
                    ],
                    "aff": [
                        {
                            "@id": "aff0",
                            "label": "0",
                            "institution": "Department of Information Science and Engineering, Sri Jayachamarajendra College of Engineering",
                            "addr-line": "Mysuru",
                            "country": {
                                "@country": "IN",
                                "#text": "India"
                            },
                            "#text": ",\n          \n          ,"
                        },
                        {
                            "@id": "aff1",
                            "label": "1",
                            "institution": [
                                "a Department of Information ScJiSenScReeasnedarEchngFionuenerdiantgio",
                                "llIengdeiaof Engineering"
                            ],
                            "addr-line": [
                                "nS,riJSJaSyTaIchCaammapruasj,enMdyrsauCruo",
                                "Mysuru"
                            ],
                            "country": {
                                "@country": "IN",
                                "#text": "India"
                            },
                            "#text": ",\n          \n          ,\n          \n          ,\n          \n          ,"
                        },
                        {
                            "@id": "aff2",
                            "label": "2",
                            "institution": "a JSS Research Foundation, JSS TI Campus, Mysuru, India Department of Information Science and Engineering, Sri Jayachamarajendra College of Engineering",
                            "addr-line": "Mysuru",
                            "country": {
                                "@country": "IN",
                                "#text": "India"
                            },
                            "#text": ",\n          \n          ,"
                        },
                        {
                            "@id": "aff3",
                            "label": "3",
                            "institution": "a, b H M Keerthi Kumar B S Harish JSS Research Foundation, JSS TI C"
                        }
                    ]
                },
                "pub-date": {
                    "year": "2018"
                },
                "volume": "00",
                "issue": "2018",
                "fpage": "000",
                "lpage": "000",
                "abstract": {
                    "p": "KCeoymwpourtdins:g SanardcaCs mom;Cmlausnsificcaatitioonn;(IFCeaAtuCreCS-2el0e1ct8io).n; k-means clustering. IAnbrsetcreancttdecades, social media sites such as twitter, facebook, and review site produces huge number of textual information posted Ibnyrmecaennyt duesceards.esT,hseocuisaelrmtednidasstiotesexsupcrehssashtiws/ihtteerr,sfeancteimboeonkt,ianntdhreevfoierwm soitfesparrocdaustciecsuhtutegreanncuems.bTerhoefstaerxctausatlicinufottremraantcioenupsousatlelyd In recent decades, social media sites such as twitter, facebook, and review site produces huge number of textual information posted sbhyifmtsatnhye upsoelrasr.itTyhoef utseexrt tfernodms ntoegeaxtipvreestso hpios/shiteirveseanntdimleiknetwi niseth.eThfoer mautoofmsatriccasctliacssuitfitecraatinocneso.fTshaercsaasrtcicasutitcteruatntecreasncpereusseunatlliyn by many users. The user tends to express his/her sentiment in the form of sarcastic utterances. The sarcastic utterance usually tsehxifttsisthaevpeorylarcihtyalolefntgeexttafsrokm.Itneregqautiivrestoa psoysitteimve tahnadt cliaknewmisaen.agTehetoaudteotmecatticconcltaesnstifibcaasteidonteoxft sparrocpaesrtitciesutoterrafneacteusrepsrepsreensteinnt shifts the polarity of text from negative to positive and likewise. The automatic classification of sarcastic utterances present in itenxstairscaastviceruyttcehra nllceensg.eIntatshki.s Irtegreaqrdu,irtehse apaspyestrepmrotphoastecannomvaenlaagpeprtoadchetetoctcclaosnstiefnyt sbaarcseadstitcextetxptroupsienrgtiecsonotrenfetabtuasresd pfereastuenret text is a very challenge task. It requires a system that can manage to detect content based text properties or features present isnelesacrticoanstmiceut httoedra.nTchees.pIrnoptohsisedreagpaprrdo,atchhe cpoanpseirstpsroofptowseo astangoevefelaatpuprerosaeclhectoiocnlamsseitfhyodsatrocassetliecct emxtosutsrinepgrecsoenntteanttivbeafseeadtufreeast.uIrne in sarcastic utterances. In this regard, the paper propose a novel approach to classify sarcastic text using content based feature sfierlsetcsttiaognem,ceothnovde.ntTiohneaplrfoepaotusered saeplpercotiaocnh mcoenthsiosdts osufctwhoasstCagHeI-fseqautuare,seInlefcotrimonatmioenthGoadinto(IsGel)ecatnmdoMsturtuepalreIsnefnotramtiavteiofnea(tMurIe)s.aIrne selection method. The proposed approach consists of two stage feature selection method to select most representative features. In ufisrsetdsttoagse,leccotnrveelenvtaionntafleafetuarteusresusbelseect.tiTohnemseltehcotdesd sfuecahturaes sCuHbsIe-stqaurearfeu,rIthneforrrmefiantieodnuGsianign s(eIGco)nadnsdtaMgeu.tuInalseIncofonrdmsattaigoen, (kM-mI)eaanres first stage, conventional feature selection methods such as CHI-square, Information Gain (IG) and Mutual Information (MI) are culsuesdtetroinsgelaelcgtorreiltehvmanitsfuesaetudrteos seulbescettm.Tohset rseeplerecstedntfaetaivtuerfeeasutubrseetamaroenfgurstihmerilraerfifneeadtuuressin.gThsecsoenledcstetadgfee.aItnurseescoanredcsltaasgseifi,ked-muesaings used to select relevant features subset. The selected feature subset are further refined using second stage. In second stage, k-means tcwluostcelrainssgifiaelgrsorSituhpmpoisrtuVsedcttoor sMelaechtimneos(tSrVepMre)seantdatRivaenfdeoamturFeoarmesotn(gRFsi)m.Tilahrefpearotuproesse.dThapepsreolaechtedoufte-apteurrfeosrmaraenccleastshiefieedxiussting clustering algorithm is used to select most representative feature among similar features. The selected features are classified using tmweothcoldassiinfietersrmSsuopfpoPrtecViesicotonr, RMeaccahlli,nFe-m(SeVaMsu)reaonnd ARmanadzoomn pFrordeusctt(rReFvi)e.wThdeatpasroetp.osed approach out-performance the existing Selection and peer-review under responsibility of the scientific committee of the 8th International Conference on Advances in"
                },
                "kwd-group": {
                    "kwd": [
                        "Sarcasm",
                        "Classification",
                        "Feature Selection",
                        "k-means clustering"
                    ]
                }
            }
        },
        "body": {
            "sec": [
                {
                    "@id": "sec-1",
                    "title": "-",
                    "p": "www.elsevier.com/locate/procedia\nb\nb\nb\nb\nb\ntwo classifiers Support Vector Machine (SVM) and Random Forest (RF). The proposed approach out-performance the existing\nmethods in terms of Precision, Recall, F-measure on Amazon product review dataset."
                },
                {
                    "@id": "sec-2",
                    "title": "1. Introduction"
                },
                {
                    "@id": "sec-3",
                    "title": "1. Introduction"
                },
                {
                    "@id": "sec-4",
                    "title": "1. Introduction",
                    "p": [
                        {
                            "xref": {
                                "@ref-type": "bibr",
                                "@rid": "ref20",
                                "#text": "20"
                            },
                            "#text": "In internet era, advance in usage of social media sites such as twitter, facebook, and review site produces a large\nIn internet era, advance in usage of social media sites such as twitter, facebook, and review site produces a large\namount of textual information. The textual information serves as a vital source to identify public/user?s opinion or\namount of textual information. The textual information serves as a vital source to identify public/user?s opinion or\nsentiment towards political party, products or an event [\n        \n        ]. The sentiments expressed by public/users are in the form"
                        },
                        {
                            "xref": [
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref20",
                                    "#text": "20"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref20",
                                    "#text": "20"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref7",
                                    "#text": "7"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref7",
                                    "#text": "7"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref7",
                                    "#text": "7"
                                }
                            ],
                            "#text": "In internet era, advance in usage of social media sites such as twitter, facebook, and review site produces a large\namount of textual information. The textual information serves as a vital source to identify public/user?s opinion or\nsentiment towards political party, products or an event [\n        \n        ]. The sentiments expressed by public/users are in the form\nof positive, negative or neutral polarity. The textual information in social media sites plays a crucial role in decision\nsentiment towards political party, products or an event [\n        \n        ]. The sentiments expressed by public/users are in the form\nof positive, negative or neutral polarity. The textual information in social media sites plays a crucial role in decision\nsupport systems and individual decision makers [\n        \n        ]. The process of automating identification of sentiment in a text is\nof positive, negative or neutral polarity. The textual information in social media sites plays a crucial role in decision\nsupport systems and individual decision makers [\n        \n        ]. The process of automating identification of sentiment in a text is\nknown as Sentiment Analysis (SA).\nsupport systems and individual decision makers [\n        \n        ]. The process of automating identification of sentiment in a text is\nknown as Sentiment Analysis (SA).\nknown as Sentiment Analysis (SA)."
                        },
                        {
                            "xref": [
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref15",
                                    "#text": "15"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref2",
                                    "#text": "2"
                                }
                            ],
                            "#text": "? Corresponding author.\nSentiment analysis (SA) is considered as a classification task, which classifies text into positive, negative or neutral\npolarity. Many characters influences SA process in social media sites namely: (a) characters limits in blogs, (b) use\nof slang words, (c) use of non-literal language, such as irony/sarcasm and many more. The major challenge in SA is\npresent of irony/sarcasm in text, which literally shifts the polarity of the sentences. Sarcasm is a sophisticated form of\nsentiment which acts as an interfering factor that can flip the polarity of the text [\n        \n        ]. Sarcasm is often characterized\nas ironic content which is used to insult, mock, or amuse. The process of identifying and classification of sarcastic\ncontent present in a text is known as sarcasm detection/classification [\n        \n        ]."
                        },
                        {
                            "xref": [
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref6",
                                    "#text": "6"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref19",
                                    "#text": "19"
                                }
                            ],
                            "#text": "Recently automatic sarcasm detection has attracted the attention of research fraternity from both Machine Learning\n(ML) and Natural Language Processing (NLP) domains [\n        \n        ][\n        \n        ]. NLP based approach uses linguistic features and\nlexicon corpus to understand the subjective information. On the other hand, ML approaches uses supervised or\nunsupervised learning techniques for understanding sarcastic sentence based on label or unlabeled text.\nIn sarcasm detection, linguistic and content based text properties or features play a vital role in deciding a text is\nsarcastic or not. Linguistic feature concentrate more on punctuations, patterns, hyperbole, ellipsis etc. On the other\nhand, content based text property more rely on the term or words appear in the text. In this paper, content based text\nproperties are used to extract more discriminative terms or features to classify a text into sarcastic or non-sarcastic\ncontent."
                        },
                        "The social media site contains large volume of textual data which outrages human?s ability to understand and\nhandle. ML plays an important role to discover patterns for such high dimensionality data. It is a challenging task for\nML algorithms to find relevant and non-redundant data from social media sites, which exhibits the characteristics\nof variety, veracity and volume of data. While performing data preprocessing and representation, a huge number of\nunfamiliar terms or features are collected. These unfamiliar features may consist of irrelevant and redundant features,\nwhich significantly increase the computational cost of learning process. Whenever the dimensionality of data is high\nits computational cost will also be high, which intern tends to decline the accuracy of ML algorithm. Hence, the curse\nof dimensionality is solved by selecting relevant and non-redundant features. The process of selecting relevant and\nnon-redundant features is known as feature selection method. The feature selection methods become more scalable,\nreliable and accurate by selecting discriminative features from unfamiliar relevant features.",
                        {
                            "xref": [
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref15",
                                    "#text": "15"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref14",
                                    "#text": "14"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref4",
                                    "#text": "4"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref5",
                                    "#text": "5"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref10",
                                    "#text": "10"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref17",
                                    "#text": "17"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref11",
                                    "#text": "11"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref13",
                                    "#text": "13"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref18",
                                    "#text": "18"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref12",
                                    "#text": "12"
                                }
                            ],
                            "#text": "Many research community [\n        \n        ][\n        \n        ][\n        \n        ][\n        \n        ][\n        \n        ] concentrated their work on the feature selection such as CHI-square\n[\n        \n        ], Information Gain (IG) [\n        \n        ], Mutual Information (MI) [\n        \n        ] and many more on social media textual data. Tripathy\net al., in [\n        \n        ] presented classification of sentiment reviews using n-gram features. The method extracts features based\non uni-gram, bi-gram, trigram and their combinations with Term frequency - Inverse document frequency (TF-IDF)\nschema. The methods are classified using machine learning algorithms such as Nave Bayes (NB), Maximum Entropy\n(ME), Stochastic Gradient Descent (SGD), and Support Vector Machine (SVM). Mukherjee et al., in [\n        \n        ] extracted\nfeatures based on content word, function word, part of speech tags and their combination to detect sarcastic content.\nThe method tests a range of different feature sets using NB and Fuzzy C-means (FCM) to classify tweet into sarcastic\nor non-sarcastic content over tweeter data."
                        },
                        {
                            "xref": [
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref14",
                                    "#text": "14"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref3",
                                    "#text": "3"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref9",
                                    "#text": "9"
                                }
                            ],
                            "#text": "Reganti et al., in [\n        \n        ] briefed automatic sarcasm detection in tweets, product reviews and newswire articles. The\nmethod extracts generic features based on lexicon and baseline features. The baseline feature such as character\nngrams, word n-grams, word skipgrams are extracted and combine with lexicon features. The methods are classified\nusing ensemble classifier such as Logistic Regression (LR), Decision Tree (DT) and Random Forest (RF) classifiers.\nBuschmeier et al., in [\n        \n        ] described the impact of features in classification of irony detection in product reviews. The\nmethod extracts text feature based on Bag-of-Words (BoW) features and lexicon based features. The methods are\nclassified using SVM, LR, DT, RF and NB classifiers. Similarly, Filatova in [\n        \n        ] demonstrated the sentiment flow\nshifts (from negative to positive and likewise) in sarcasm detection. The method captures the presence of sarcasm in\nproduct reviews and identifies the shift in polarity of sentiment label assigned to the product reviews. The method\nclassifies polarity using K-Nearest Neighbor (KNN), SVM (Linear and Radial Basis Function), DT, RF, AdaBoost\nand LR classifiers."
                        },
                        {
                            "xref": [
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref4",
                                    "#text": "4"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref5",
                                    "#text": "5"
                                },
                                {
                                    "@ref-type": "bibr",
                                    "@rid": "ref16",
                                    "#text": "16"
                                }
                            ],
                            "#text": "Chakraborty et al., in [\n        \n        ] provides an insight on process of learning representation or features using Deep Learning\non Word2vec model. The model uses two diverse essences such as Continuous Bag-of-Words model (CBOW) and\nSkip-Gram on IMDB movie reviews. The comparative analysis are drawn on performance of k-means and k-means++\nclustering algorithm. Similarly, Chormunge and Jena in [\n        \n        ], proposed feature selection based on correlation based\nfeature selection with Clustering for high dimensional data. The feature selection method eliminates irrelevant features\nby using k-means clustering method and then non-redundant features are selected by correlation measure from each\ncluster. The methods are compared with renowned feature selection method such as ReliefF and Information Gain\n(IG) methods using NB classifier. Sarkar et al., in [\n        \n        ] presented a novel feature selection method for text\nclassification. The method uses two layer of feature selection based on CHI-square feature selection method and clustering\ntechnique to select more discriminative features. The extracted feature subsets are classified using NB, DT, SVM and\nKNN classifiers."
                        },
                        {
                            "xref": {
                                "@ref-type": "bibr",
                                "@rid": "ref8",
                                "#text": "8"
                            },
                            "#text": "In literature, many researchers used various feature selection methods to select relevant features from high\ndimensionality feature space. The existing work concentrates more on dimensionality reduction by selecting relevant features\nusing feature selection methods. The main objective of this paper is to present two stage feature selection method\nto select most representative features. The feature selection method selects the relevant feature subset from high\ndimensionality feature space. However, selected feature subset may have features which convey similar information.\nThe features exhibits similar information can be grouped and most representative features can be selected. Due to\nthis reason, the proposed work applies two stage feature selection method to select representative features. In first\nstage, conventional feature selection method such as CHI-square, IG and Mutual Information (MI) are used to select\nrelevant features subset. The selected feature subset from conventional feature selection methods are further refined\nusing second stage. In second stage, k-means clustering algorithm is used to select most representative feature among\nsimilar features. The selected features are classified using various classifiers such as SVM and RF classifiers on\nAmazon product review dataset [\n        \n        ]."
                        },
                        "The rest of the paper is organized as follows: Section 2 depicts the methodology of the proposed model. The detailed\nexperimental results and discussion are presented in section 3. Finally, the paper concludes with stating future scopes\nin section 4."
                    ]
                },
                {
                    "@id": "sec-5",
                    "title": "2. Methodology",
                    "p": "This section depicts the detailed description of methodology of the proposed two stage feature selection method.\nThe proposed model is used to select more representative features to classify text into sarcastic or non-sarcastic\ncontents. The block diagram of the proposed model is presented in Fig. 1.\nThe various steps involved in proposed method are: Firstly, the raw text data is preprocessed using various\npreprocessing techniques. Further, features are extracted and represented using uni-gram representation with term frequency\nschema. The extracted features are in high dimension, which need to be reduced or refined using feature selection\nmethods. The proposed feature selection method is applied to select more discriminative features. The proposed\nfeature selection method uses two stages of feature selection. In first stage, conventional feature selection such as\nCHIsquare (?2), Information Gain (IG) and Mutual Information (MI) methods are used to select discriminative features.\nThe selected features are further refined in second stage of feature selection. In second stage, k-means clustering\nalgorithm is used to select most representative features from feature subset selected in first stage feature selection method.\nThe k-means clustering algorithm is one of the simplest and most popular clustering techniques, which clusters similar\ninformation into k number of groups or cluster. Hence, in this work k-means clustering algorithm is used to select most\nrepresentative features of each group. Finally, the feature subset obtained using proposed feature selection method is\nclassified using two classifiers such as SVM and RF classifiers.",
                    "sec": [
                        {
                            "@id": "sec-5-1",
                            "title": "2.1. Preprocessing",
                            "p": "During preprocessing, non-trivial and less informative terms are eliminated, which doesn?t contribute to the\nclassification processes. Initially, words are converted into lower case and then various preprocessing techniques are applied.\nIn this work, the product reviews are preprocessed by eliminating stop words, digits and punctuations. The\npreprocessed reviews are represented using uni-gram representation model with term frequency (t f ) schema. Let m be the\nnumber of reviews and n be the number of terms or features represented in Term Document Matrix (T DM). The entry\nT DMi j indicates the corresponding t f of ith review of jth feature."
                        },
                        {
                            "@id": "sec-5-2",
                            "title": "2.2. Proposed Feature Selection Method",
                            "p": "The proposed feature selection method consists of two stages: In first stage, the conventional feature selections\nmethod is used to select relevant feature subsets. The conventional feature selection methods such as CHI-square\n(?2), Information Gain (IG) and Mutual Information (MI) feature selection methods are used. These features selection\nmethods are widely used to select relevant feature subset in text processing domain. The Chi-square (?2) is used\nto test whether the occurrence of a specific term and the occurrence of a specific class are independent. IG gives\nthe information that?s gained by knowing the value of the attribute, which is the difference between entropy of the\ndistribution before the split and the entropy of the distribution after split. Similarly, MI calculates mutual dependence\nof the two random variables. The outcome of each feature selection method will be scores (S ) corresponding to each\nfeature. The scores (S ) are arranged in descending order to select most relevant features which contain high feature\nscore. The feature subsets are selected by fixing threshold value (T ) empirically. The selected features subset using\nconventional feature selection method is represented using Term Document Matrix T DM (m \u00d7 T ) where m represent\nnumber of reviews and T indicates number of feature subset selected from feature selection methods. The selected\nfeature subset (T ) may have features which convey similar information. To select most representative features among\nthe feature subset (T ), second stage feature selection method are applied. Algorithm 1 depicts the first stage feature\nselection method.",
                            "sec": [
                                {
                                    "@id": "sec-5-2-1",
                                    "title": "Algorithm 1: First stage of Feature selection method",
                                    "p": [
                                        "Data: Term Document Matrix T DM (m \u00d7 n), m number of reviews, n total number of features, Features scores",
                                        "S , F number of features\nResult: Term Document Matrix T DM (m \u00d7 T )\nInitialize threshold value to T;\nStep 1: S =FS method [T DM]\nStep 2: S ={s1, s2, ...., sn}\nStep 3: Sort S in descending order\nStep 4: Select first T number of features based on S\nStep 5: F = {F1, F2, ...., FT}",
                                        "compute score for each feature using CHI, MI and IG feature selection methods\nSelected features subset using feature selection method are represented in Term Document Matrix T DM (m \u00d7 T ),\nwhere m represent number of reviews and T indicates number of feature subset selected from feature selection method.\nFurther, we transpose T DM (T \u00d7 m), where each row represents number of features T and column indicates number\nof reviews m.",
                                        {
                                            "xref": {
                                                "@ref-type": "bibr",
                                                "@rid": "ref16",
                                                "#text": "16"
                                            },
                                            "#text": "In second stage, similarity based algorithm is used to select most representative feature. In this work, similarity\nbased k-means clustering algorithm is used to select most representative feature from each clusters (k). The most\nrepresentative features from each cluster are selected based on the feature nearer to its cluster center. The algorithm\nworks iteratively to assign features to one of the k cluster based on the similar features. To determine the optimal\nnumber of cluster (k) is one of the open question in clustering. In this work, the number of cluster (k) is initialized\nto threshold value (NC), where NC is number of clusters varied from ?T to T as mentioned in [\n            \n            ]. Algorithm 2\n2\nend\nend\nStep 3: Assign F j to nearest cluster center vi\nStep 4: Update cluster center\nStep 5: for i ? to 1 by NC do"
                                        },
                                        "F j\nv(t + 1)= j=i\ni",
                                        "| vi |\nend\nuntil v(t ? 1) - v(t) < ?, t=t+1;\nStep 6: for i ? to 1 by NC do",
                                        "Step 7:F j=min j dist j ? i(vi, F ji)",
                                        "Step 8: F=F ? F j\nend\nfind representative feature for each cluster center\nelucidates second stage Feature selection method."
                                    ]
                                },
                                {
                                    "@id": "sec-5-2-2",
                                    "title": "Algorithm 2: Second stage of Feature selection method",
                                    "p": [
                                        "Data: Term Document Matrix T DM (T \u00d7 m), T total number of features, m number of reviews, number of\ncluster NC= ?T to T",
                                        "2\nResult: Term Document Matrix T DM (m \u00d7 NC)\nInitialize NC number of cluster center, t=0, F={ }, V0 = {V10, V02, ...., V0NC}\nrepeat",
                                        "Step 1: for i ? to 1 by NC do",
                                        "Step 2: for j ? to 1 by T do",
                                        "Di j = dist(Vti,F j) compute distance between cluster center and feature F j (Euclidean norm is used\nto calculate the distance)\nFurther, the feature subset F, which consists of NC number of features are represented in Term Document Matrix\nT DM(m \u00d7 NC), where m is the number of reviews and NC is the number features (NC < T < n)."
                                    ]
                                }
                            ]
                        },
                        {
                            "@id": "sec-5-3",
                            "title": "2.3. Classification",
                            "p": {
                                "xref": [
                                    {
                                        "@ref-type": "bibr",
                                        "@rid": "ref21",
                                        "#text": "21"
                                    },
                                    {
                                        "@ref-type": "bibr",
                                        "@rid": "ref1",
                                        "#text": "1"
                                    },
                                    {
                                        "@ref-type": "bibr",
                                        "@rid": "ref3",
                                        "#text": "3"
                                    },
                                    {
                                        "@ref-type": "bibr",
                                        "@rid": "ref14",
                                        "#text": "14"
                                    }
                                ],
                                "#text": "In order to determine the efficacy of the proposed feature selection method, the two classifiers linear Support Vector\nMachine (SVM) and Random Forest (RF) classifiers are used. The SVM is a statistical classification approach which\ncan be used for both classification and regression challenges [\n          \n          ]. On the other hand, RF is an automatic learning\ntechnique which combines the concepts of random subspaces and bagging [\n          \n          ]. These two classifiers are widely used\nin classification of sarcastic content [\n          \n          ][\n          \n          ]."
                            }
                        }
                    ]
                },
                {
                    "@id": "sec-6",
                    "title": "3. Experimental Result and Discussion",
                    "sec": [
                        {
                            "@id": "sec-6-1",
                            "title": "3.1. Dataset",
                            "p": [
                                "This section describes the details of the experiment conducted to evaluate the proposed feature selection method.",
                                {
                                    "xref": {
                                        "@ref-type": "bibr",
                                        "@rid": "ref8",
                                        "#text": "8"
                                    },
                                    "#text": "The experiment is conducted on Amazon product reviews created by [\n          \n          ] using crowd sourcing platform Amazon\nMechanical Turk. The dataset consists of 1,254 Amazon product reviews, which consists of 437 sarcastic and 817\nnon-sarcastic reviews. The structure of the dataset contains star-rating and the reviews. Here, star-rating are ranged\nbetween 1star to 5star and review text are in English language."
                                }
                            ]
                        },
                        {
                            "@id": "sec-6-2",
                            "title": "3.2. Experimental setup",
                            "p": {
                                "xref": {
                                    "@ref-type": "bibr",
                                    "@rid": "ref8",
                                    "#text": "8"
                                },
                                "#text": "In this work, experiments are conducted using 80:20 split on Amazon product review dataset [\n          \n          ]. The various\npreprocessing techniques are applied on Amazon product review dataset. Once the dataset is preprocessed, the terms are\nrepresented using unigram with term frequency (t f ) schema. The total number of features obtained are 20,985\ndistinct features. Further, the proposed feature selection method is applied on the 20,985 distinct features. The proposed\nfeature selection method consists of two stages: In first stage, feature subsets are selected in between 1,000 to 20,000\nfeatures by empirically. During this process, 10000 feature subset yield promising results compared to other feature\nsubsets. In second stage, k-means clustering is used to select most representative feature subset from first stage feature\nselection method. The number of cluster (k) is varied from 1000 to 5000 as explained in section 2.2. The obtained\nfeature subsets from second stage are classified using linear Support Vector Machine (SVM) and Random Forest (RF)\nclassifiers. We initialized number of trees to 100 in RF classifier by empirically. The performance of proposed feature\nselection method is evaluated using classification accuracy and F-measure as a metric."
                            }
                        },
                        {
                            "@id": "sec-6-3",
                            "title": "3.3. Experimental results",
                            "p": [
                                "To report the performance of various classifiers, experiments are varied in number of features from 1,000 to 20,000\nusing CHI-square (?2), Information Gain (IG) and Mutual Information (MI) feature selection methods and found\n10000 feature numbers yield competitive accuracy compared to other feature sets. Hence, experiments are conducted\non 10000 features in first stage of feature selection method. The Table 1 shows the performance of the classifiers on\noriginal Term Document Matrix (T DM) and various feature selection methods. MI with 10000 features gives 75.60%\nclassification accuracy with 0.675 F-measure compared to other feature selection methods using SVM classifier.\nSimilarly, IG with 10000 features gives 72.40% classification accuracy with F-measure of 0.595 for RF classifiers.\nFurther, k-means clustering algorithm is applied on 10000 features obtained from feature selection methods. As\nexplained in section 2.2, the numbers of cluster are varied from 1000 to 5000. The Fig. 2 depicts the classification\naccuracy of proposed method with various number of cluster using SVM and RF classifiers. From Fig. 2 (a), we\nobserved that the CHI-square with k-means achieve maximum accuracy for 4500 feature set, IG with k-means gives\nmaximum accuracy for 5000 feature set compared to respective feature set using SVM classifier. Similarly, MI with\nk-means yield maximum accuracy for 5000 feature set compared to other feature set and other combinations using\nSVM classifier. On the other hand, Fig. 2 (b) depicts the results of various feature selection methods for different\nnumber of cluster in k-means using RF classifier. The MI with k-means yield maximum accuracy for 3000 feature subset\ncompared to CHI-square with k-means for 4000 and IG with k-means for 3000 feature subset using RF classifier.\nFurther, table 2 depicts the performance of proposed approach (feature selection + clustering) using SVM and RF\nclassifiers. The proposed method (MI + k-means) for 5000 number of features achieve highest classification accuracy\nof 79.40% and 0.711 F-measure using SVM classifier. On the other hand, proposed method (MI + k-means) achieves\n77.20% classification accuracy and 0.696 F-measure for 4500 number of features using RF classifier. From table 2, the\nproposed method (MI + k-means) outperforms in term of number of features, classification accuracy and F-measure\ncompared to other feature selection combinations using SVM and RF classifiers.",
                                "The table 3 summarizes results of proposed method in terms of reduction in number of features along with\nimprovement in classification accuracy. The proposed method (MI + k-means) exhibits 86% of reduction with 3000 number\nof features compared to original features (20985), which intern enhances the classification accuracy by 11% using\nRF classifier. On the other hand, the proposed method (MI + k-means) achieve 76% reduction in number of features\n(5000) with increase of classification accuracy by 16% using SVM classifier."
                            ]
                        },
                        {
                            "@id": "sec-6-4",
                            "title": "3.4. Comparisons with existing methods",
                            "p": [
                                {
                                    "xref": [
                                        {
                                            "@ref-type": "bibr",
                                            "@rid": "ref3",
                                            "#text": "3"
                                        },
                                        {
                                            "@ref-type": "bibr",
                                            "@rid": "ref14",
                                            "#text": "14"
                                        },
                                        {
                                            "@ref-type": "bibr",
                                            "@rid": "ref8",
                                            "#text": "8"
                                        },
                                        {
                                            "@ref-type": "bibr",
                                            "@rid": "ref9",
                                            "#text": "9"
                                        },
                                        {
                                            "@ref-type": "bibr",
                                            "@rid": "ref3",
                                            "#text": "3"
                                        },
                                        {
                                            "@ref-type": "bibr",
                                            "@rid": "ref14",
                                            "#text": "14"
                                        }
                                    ],
                                    "#text": "From literature, Buschmeier et al. [\n          \n          ] and Reganti et al. [\n          \n          ], elucidates sarcasm/irony detection on product review\ndataset [\n          \n          ] using SVM and RF classifier. The similar sets of experiments are conducted and comparison results are\npresented in Table 4. However, same dataset is used for various purposes using different approaches [\n          \n          ]. Hence,\nthe proposed approach is compared with [\n          \n          ] and [\n          \n          ] in Table 4. The proposed method (MI + k-means) with 5000\nnumber of feature set exhibits maximum performance in term of Precision, Recall and F-measure using SVM classifier.\nSimilarly, proposed method (MI + k-means) with 3000 number of feature depicts maximum performance in Precision,\nRecall and F-measure using RF classifier."
                                },
                                {
                                    "xref": {
                                        "@ref-type": "bibr",
                                        "@rid": "ref14",
                                        "#text": "14"
                                    },
                                    "#text": "The table 4 elucidates the comparisons of proposed method with existing methods. In Reganti et al. [\n          \n          ], the baseline\nfeatures such as character n-grams, word n-grams, word skipgrams are used but total number of feature are not stated\nclearly. Hence, proposed method is compared with F-measure metric obtained from SVM and RF classifier. From\ntable 4, it can be concluded that the proposed method outperforms the existing methods in terms of Precision, Recall,\nF-measure using SVM and RF classifiers."
                                },
                                "Fmeasure\n0.329"
                            ]
                        },
                        {
                            "@id": "sec-6-5",
                            "title": "3.5. Result Analysis and Discussion",
                            "p": "The feature selection method reduce the high dimensionality feature space by selecting relevant features set from\noriginal features based on scores. However, selected feature subset may have features which convey similar\ninformation. To select most representative features among selected feature subset, two stage feature selection method is\napplied. The advantage of proposed two stage feature selection method is to select most representative features which\nconvey similar information among feature subset. The proposed method uses two stage feature selection method\nusing conventional feature selection method and k-means similarity clustering algorithm. The performance of proposed\nmethod (conventional feature selection method with k-means) depends on the feature set selected using first stage. In\nfirst stage, features depend on the feature selection algorithm used. In this experiment, the conventional feature\nselection methods such as CHI-square (?2), Information Gain (IG) and Mutual Information (MI) feature selection methods\nare used. It is noticeable from table 1, that first stage feature selection method using conventional feature selection\nmethod reduces the high dimensionality feature space, which intern increases the classification accuracy of the\nclassifiers. The MI and IG feature selection method yields maximum accuracy using SVM and RF classifiers, respectively.\nThe CHI-square (?2) is used to measure the lack of independence between the specific term and the specific class.\nIG gives the information gained by knowing the value of the attribute, which is the difference between entropy of\nthe distribution before the split and the entropy of the distribution after split. Similarly, MI calculates mutual\ndependence of the two random variables. In second stage feature selection method, k-means clustering algorithm groups the\nsimilar features into specified number of clusters. Here, features are grouped based on the similarities which convey\nsimilar information. The most representative feature of each cluster, which is nearer to cluster centers are selected.\nThe Fig. 2 (a) and 2 (b) presents the variation of classification accuracy from 1000 to 5000 features set using SVM\nand RF classifiers. The MI with k-means consistently outrages other feature selection combinations using SVM and\nRF classifiers. The MI with k-means yields promising results compared to other combination because MI compares\nthe probability of observing feature and class together (the joint probability) instead of observing feature and class\nindependently. Due to this reason, MI accumulates the similar information features together. On the other hand,\nkmeans groups the similar information, which intern reduces the feature spaces with increasing classification accuracy.\nHence, the combination of these methods exhibits maximum accuracy on both the classifiers. The table 2 depicts\ncomparisons of various feature selection with k-means algorithm. From table 2 results, the proposed method reduces the\nnumber of features set with increasing classification accuracy. A crucial observation is note in table 3, which depicts\nthe summary of percentage reduction in features and the improvement of classification accuracy in proposed method.\nTo evaluate the proposed method in table 4, the proposed method is compared with the existing methods. From table\n4, it can be concluded that the proposed method outperforms other existing methods in classifying sarcastic content\npresent in product review dataset."
                        }
                    ]
                },
                {
                    "@id": "sec-7",
                    "title": "4. Conclusion and Future work",
                    "p": [
                        "In this work, we propose a novel approach to classify sarcastic text using content based feature selection method.\nThe proposed approach consists of two stage feature selection method to select most representative features. In first\nstage, conventional feature selection methods are used to select relevant features subset. The selected feature subset\nfrom conventional feature selection methods such as CHI-square, IG and Mutual Information (MI) are further refined\nusing second stage. In second stage, k-means clustering algorithm is used to select most representative feature among\nsimilar features. The selected features are classified using various classifiers such as SVM and RF classifiers. The\nresults of the proposed approach (MI + clustering) outperform the exiting methods in terms of Precision, Recall,\nFmeasure on benchmark dataset.",
                        "In future, the proposed work can be extended to (a) n-gram (bi-gram, trigram) representation, (b) various feature\nselection methods and (c) variance of k-means clustering techniques along with different classifiers which enhances the\nclassification accuracies. Further, the proposed approach can be also extended to various fields such as text\nclassification, sentiment analysis, information retrieval and many more."
                    ]
                },
                {
                    "@id": "sec-8",
                    "title": "Acknowledgements"
                }
            ]
        },
        "back": {
            "ref-list": {
                "ref": [
                    {
                        "@id": "ref1",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "given-names": "Al",
                                    "surname": "Amrani"
                                },
                                {
                                    "given-names": "Y.",
                                    "surname": "Lazaar",
                                    "#text": ","
                                },
                                {
                                    "given-names": "M.",
                                    "surname": "El Kadiri",
                                    "#text": ","
                                },
                                {
                                    "surname": "K.E."
                                }
                            ],
                            "year": "2018",
                            "article-title": "Random forest and support vector machine based hybrid approach to sentiment analysis",
                            "source": "Procedia Computer Science",
                            "volume": "127",
                            "fpage": "511",
                            "lpage": "520",
                            "#text": "[1]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref2",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Bharti",
                                    "given-names": "S.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Vachha",
                                    "given-names": "B.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Pradhan",
                                    "given-names": "R.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Babu",
                                    "given-names": "K.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Jena",
                                    "given-names": "S.",
                                    "#text": ","
                                }
                            ],
                            "year": "2016",
                            "article-title": "Sarcastic sentiment detection in tweets streamed in real time: a big data approach",
                            "source": "Digital Communications and Networks",
                            "volume": "2",
                            "fpage": "108",
                            "lpage": "121",
                            "#text": "[2]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref3",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Buschmeier",
                                    "given-names": "K.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Cimiano",
                                    "given-names": "P.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Klinger",
                                    "given-names": "R.",
                                    "#text": ","
                                }
                            ],
                            "year": "2014",
                            "article-title": "An impact analysis of features in a classification approach to irony detection in product reviews",
                            "source": "in: Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
                            "fpage": "42",
                            "lpage": "49",
                            "#text": "[3]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          ,\n          \n          , pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref4",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Chakraborty",
                                    "given-names": "K.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Bhattacharyya",
                                    "given-names": "S.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Bag",
                                    "given-names": "R.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Hassanien",
                                    "given-names": "A.E.",
                                    "#text": ","
                                }
                            ],
                            "year": "2018",
                            "article-title": "Comparative sentiment analysis on a set of movie reviews using deep learning approach",
                            "source": "in: International Conference on Advanced Machine Learning Technologies and Applications",
                            "fpage": "311",
                            "lpage": "318",
                            "#text": "[4]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          ,\n          \n          , Springer. pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref5",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Chormunge",
                                    "given-names": "S.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Jena",
                                    "given-names": "S.",
                                    "#text": ","
                                }
                            ],
                            "year": [
                                "2018",
                                "2017"
                            ],
                            "article-title": "Correlation based feature selection with clustering for high dimensional data",
                            "source": "Journal of Electrical Systems and Information Technology",
                            "volume": "06",
                            "#text": "[5]\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          , doi:https://doi.org/10.1016/j.jesit.\n          \n          .\n          \n          .004."
                        }
                    },
                    {
                        "@id": "ref6",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Dave",
                                    "given-names": "A.D.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Desai",
                                    "given-names": "N.P.",
                                    "#text": ","
                                }
                            ],
                            "year": "2016",
                            "article-title": "A comprehensive study of classification techniques for sarcasm detection on textual data, in: Electrical, Electronics, and Optimization Techniques (ICEEOT",
                            "fpage": "1985",
                            "lpage": "1991",
                            "#text": "[6]\n          \n          ,\n          \n          ,\n          \n          .\n          \n          ), International Conference on, IEEE. pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref7",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Fersini",
                                    "given-names": "E.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Messina",
                                    "given-names": "E.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Pozzi",
                                    "given-names": "F.A.",
                                    "#text": ","
                                }
                            ],
                            "year": "2014",
                            "article-title": "Sentiment analysis: Bayesian ensemble learning",
                            "source": "Decision support systems 68",
                            "fpage": "26",
                            "lpage": "38",
                            "#text": "[7]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref8",
                        "mixed-citation": {
                            "string-name": {
                                "surname": "Filatova",
                                "given-names": "E.",
                                "#text": ","
                            },
                            "year": "2012",
                            "article-title": "Irony and sarcasm: Corpus generation and analysis using crowdsourcing, in: LREC, Citeseer",
                            "fpage": "392",
                            "lpage": "398",
                            "#text": "[8]\n          \n          ,\n          \n          .\n          \n          . pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref9",
                        "mixed-citation": {
                            "string-name": {
                                "surname": "Filatova",
                                "given-names": "E.",
                                "#text": ","
                            },
                            "year": "2017",
                            "article-title": "Sarcasm detection using sentiment flow shifts",
                            "source": "in: FLAIRS-30, Association for the Advancement of Artificial Intelligence",
                            "fpage": "264",
                            "lpage": "269",
                            "#text": "[9]\n          \n          ,\n          \n          .\n          \n          ,\n          \n          . pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref10",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Harish",
                                    "given-names": "B.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Revanasiddappa",
                                    "given-names": "M.",
                                    "#text": ","
                                }
                            ],
                            "year": "2017",
                            "article-title": "A comprehensive survey on various feature selection methods to categorize text documents",
                            "source": "International Journal of Computer Applications",
                            "volume": [
                                "164",
                                "10"
                            ],
                            "fpage": "1",
                            "lpage": "7",
                            "#text": "[10]\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          \n          ,\n          \n          -\n          \n          . doi:\n          \n          .5120/ijca2017913711."
                        }
                    },
                    {
                        "@id": "ref11",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Lee",
                                    "given-names": "C.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Lee",
                                    "given-names": "G.G.",
                                    "#text": ","
                                }
                            ],
                            "year": "2006",
                            "article-title": "Information gain and divergence-based feature selection for machine learning-based text categorization",
                            "source": "Information processing & management 42",
                            "fpage": "155",
                            "lpage": "165",
                            "#text": "[11]\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref12",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Mukherjee",
                                    "given-names": "S.",
                                    "#text": ","
                                },
                                {
                                    "surname": "P.K."
                                }
                            ],
                            "year": "2017",
                            "article-title": "Sarcasm detection in microblogs using na\u00a8?ve bayes and fuzzy clustering",
                            "source": "Technology in Society 48",
                            "fpage": "19",
                            "lpage": "27",
                            "#text": "[12]\n          \n          , Bala,\n          \n          ,\n          \n          .\n          \n          .\n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref13",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "J."
                                },
                                {
                                    "given-names": "A.",
                                    "surname": "Pudil",
                                    "#text": ","
                                },
                                {
                                    "surname": "P."
                                }
                            ],
                            "year": "2004",
                            "article-title": "Feature selection using improved mutual information for text classification, in: Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR",
                            "fpage": "1010",
                            "lpage": "1017",
                            "#text": "[13] Novovic?ova\u00b4,\n          \n          , Mal\u00b4?k,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          ), Springer. pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref14",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Reganti",
                                    "given-names": "A.N.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Maheshwari",
                                    "given-names": "T.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Kumar",
                                    "given-names": "U.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Das",
                                    "given-names": "A.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Bajpai",
                                    "given-names": "R.",
                                    "#text": ","
                                }
                            ],
                            "year": "2016",
                            "article-title": "Modeling satire in english text for automatic detection",
                            "source": [
                                "in: Data Mining Workshops (ICDMW)",
                                "2016 IEEE 16th International Conference on, IEEE"
                            ],
                            "fpage": "970",
                            "lpage": "977",
                            "#text": "[14]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          ,\n          \n          ,\n          \n          . pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref15",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Riloff",
                                    "given-names": "E.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Qadir",
                                    "given-names": "A.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Surve",
                                    "given-names": "P.",
                                    "#text": ","
                                },
                                {
                                    "surname": "De Silva",
                                    "given-names": "L.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Gilbert",
                                    "given-names": "N.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Huang",
                                    "given-names": "R.",
                                    "#text": ","
                                }
                            ],
                            "year": "2013",
                            "article-title": "Sarcasm as contrast between a positive sentiment and negative situation",
                            "source": "in: Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                            "fpage": "704",
                            "lpage": "714",
                            "#text": "[15]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          ,\n          \n          , pp.\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref16",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Sarkar",
                                    "given-names": "S.D.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Goswami",
                                    "given-names": "S.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Agarwal",
                                    "given-names": "A.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Aktar",
                                    "given-names": "J.",
                                    "#text": ","
                                }
                            ],
                            "year": [
                                "2014",
                                "2014",
                                "2014"
                            ],
                            "article-title": "A novel feature selection technique for text classification using naive bayes",
                            "source": "International scholarly research notices",
                            "fpage": "1",
                            "lpage": "10",
                            "#text": "[16]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          \n          ,\n          \n          -\n          \n          . doi:http://dx.doi.org/10.1155/\n          \n          /717092."
                        }
                    },
                    {
                        "@id": "ref17",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Song",
                                    "given-names": "F.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Liu",
                                    "given-names": "S.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Yang",
                                    "given-names": "J.",
                                    "#text": ","
                                }
                            ],
                            "year": "2005",
                            "article-title": "A comparative study on text representation schemes in text categorization",
                            "source": "Pattern analysis and applications 8",
                            "fpage": "199",
                            "lpage": "209",
                            "#text": "[17]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref18",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Tripathy",
                                    "given-names": "A.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Agrawal",
                                    "given-names": "A.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Rath",
                                    "given-names": "S.K.",
                                    "#text": ","
                                }
                            ],
                            "year": "2016",
                            "article-title": "Classification of sentiment reviews using n-gram machine learning approach",
                            "source": "Expert Systems with Applications",
                            "volume": "57",
                            "fpage": "117",
                            "lpage": "126",
                            "#text": "[18]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref19",
                        "mixed-citation": {
                            "string-name": {
                                "surname": "Wallace",
                                "given-names": "B.C.",
                                "#text": ","
                            },
                            "year": "2015",
                            "article-title": "Computational irony: A survey and new perspectives",
                            "source": "Artificial Intelligence Review",
                            "volume": "43",
                            "fpage": "467",
                            "lpage": "483",
                            "#text": "[19]\n          \n          ,\n          \n          .\n          \n          .\n          \n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref20",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Wang",
                                    "given-names": "G.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Sun",
                                    "given-names": "J.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Xu",
                                    "given-names": "K.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Gu",
                                    "given-names": "J.",
                                    "#text": ","
                                }
                            ],
                            "year": "2014",
                            "article-title": "Sentiment classification: The contribution of ensemble learning",
                            "source": "Decision support systems 57",
                            "fpage": "77",
                            "lpage": "93",
                            "#text": "[20]\n          \n          ,\n          \n          , Ma, J.,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          .\n          \n          ,\n          \n          -\n          \n          ."
                        }
                    },
                    {
                        "@id": "ref21",
                        "mixed-citation": {
                            "string-name": [
                                {
                                    "surname": "Witten",
                                    "given-names": "I.H.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Frank",
                                    "given-names": "E.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Hall",
                                    "given-names": "M.A.",
                                    "#text": ","
                                },
                                {
                                    "surname": "Pal",
                                    "given-names": "C.J.",
                                    "#text": ","
                                }
                            ],
                            "year": "2016",
                            "article-title": "Data Mining: Practical machine learning tools and techniques",
                            "#text": "[21]\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          ,\n          \n          .\n          \n          . Morgan Kaufmann."
                        }
                    }
                ]
            }
        }
    }
}